{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next code was launched under Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for Natural Language Processing\n",
    "\n",
    "\n",
    " * Simple text representations, bag of words\n",
    " * Word embedding and... not just another word2vec this time\n",
    " * rnn for text\n",
    " * Aggregating several data sources \"the hard way\"\n",
    " * Solving ~somewhat~ real ML problem with ~almost~ end-to-end deep learning\n",
    " \n",
    "\n",
    "Special thanks to Irina Golzmann for help with technical part, task prepared by Александр Панин, jheuristic@yandex-team.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "You will require nltk v3.2 to solve this assignment\n",
    "\n",
    "__It is really important that the version is 3.2, otherwize russian tokenizer might not work__\n",
    "\n",
    "Install/update\n",
    "* `sudo pip install --upgrade nltk==3.2`\n",
    "* If you don't remember when was the last pip upgrade, `sudo pip install --upgrade pip`\n",
    "\n",
    "If for some reason you can't or won't switch to nltk v3.2, just make sure that russian words are tokenized properly with RegeExpTokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For students with low-RAM machines\n",
    " * This assignment can be accomplished with even the low-tier hardware (<= 4Gb RAM) \n",
    " * If that is the case, turn flag \"low_RAM_mode\" below to True\n",
    " * If you have around 8GB memory, it is unlikely that you will feel constrained by memory.\n",
    " * In case you are using a PC from last millenia, consider setting very_low_RAM=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_RAM_mode = True\n",
    "very_low_RAM = False  #If you have <3GB RAM, set BOTH to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Ex-kaggle-competition on prohibited content detection\n",
    "\n",
    "There goes the description - https://www.kaggle.com/c/avito-prohibited-content\n",
    "\n",
    "\n",
    "### Download\n",
    "High-RAM mode,\n",
    " * Download avito_train.tsv from competition data files\n",
    "Low-RAM-mode,\n",
    " * Download downsampled dataset from here\n",
    "     * archive https://yadi.sk/d/l0p4lameqw3W8\n",
    "     * raw https://yadi.sk/d/I1v7mZ6Sqw2WK (in case you feel masochistic)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# What's inside\n",
    "Different kinds of features:\n",
    "* 2 text fields - title and description\n",
    "* Special features - price, number of e-mails, phones, etc\n",
    "* Category and subcategory - unsurprisingly, categorical features\n",
    "* Attributes - more factors\n",
    "\n",
    "Only 1 binary target whether or not such advertisement contains prohibited materials\n",
    "* criminal, misleading, human reproduction-related, etc\n",
    "* diving into the data may result in prolonged sleep disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not low_RAM_mode:\n",
    "    # a lot of ram\n",
    "    df = pd.read_csv(\"avito_train.tsv\",sep='\\t')\n",
    "else:\n",
    "    #aroung 4GB ram\n",
    "    df = pd.read_csv(\"avito_train_1kk.tsv\",sep='\\t')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1204949, 13) 0.228222107326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Toyota Sera, 1991</td>\n",
       "      <td>Новая оригинальная линзованая оптика на ксенон...</td>\n",
       "      <td>{\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000094</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Костюм Steilmann</td>\n",
       "      <td>Юбка и топ из панбархата. Под топ  трикотажная...</td>\n",
       "      <td>{\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000299</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>Костюм Didriksons Boardman, размер 100, краги,...</td>\n",
       "      <td>Костюм Didriksons Boardman, в отличном состоян...</td>\n",
       "      <td>{\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000309</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>Квартиры</td>\n",
       "      <td>1-к квартира, 44 м², 9/20 эт.</td>\n",
       "      <td>В кирпичном пан.-м доме, продается одноком.-ая...</td>\n",
       "      <td>{\"Тип объявления\":\"Продам\", \"Количество комнат...</td>\n",
       "      <td>2642020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000317</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Поездки на таможню, печать в паспорте</td>\n",
       "      <td>Поездки на таможню гражданам СНГ для пересечен...</td>\n",
       "      <td>{\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid      category                subcategory  \\\n",
       "0  10000010     Транспорт      Автомобили с пробегом   \n",
       "1  10000094   Личные вещи  Одежда, обувь, аксессуары   \n",
       "2  10000299   Личные вещи     Детская одежда и обувь   \n",
       "3  10000309  Недвижимость                   Квартиры   \n",
       "4  10000317        Услуги          Предложения услуг   \n",
       "\n",
       "                                               title  \\\n",
       "0                                  Toyota Sera, 1991   \n",
       "1                                   Костюм Steilmann   \n",
       "2  Костюм Didriksons Boardman, размер 100, краги,...   \n",
       "3                      1-к квартира, 44 м², 9/20 эт.   \n",
       "4              Поездки на таможню, печать в паспорте   \n",
       "\n",
       "                                         description  \\\n",
       "0  Новая оригинальная линзованая оптика на ксенон...   \n",
       "1  Юбка и топ из панбархата. Под топ  трикотажная...   \n",
       "2  Костюм Didriksons Boardman, в отличном состоян...   \n",
       "3  В кирпичном пан.-м доме, продается одноком.-ая...   \n",
       "4  Поездки на таможню гражданам СНГ для пересечен...   \n",
       "\n",
       "                                               attrs    price  is_proved  \\\n",
       "0  {\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...   150000        NaN   \n",
       "1  {\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...     1500        NaN   \n",
       "2  {\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...     3000        NaN   \n",
       "3  {\"Тип объявления\":\"Продам\", \"Количество комнат...  2642020        NaN   \n",
       "4  {\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...     1500        0.0   \n",
       "\n",
       "   is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "0           0           0           0         0         0.03  \n",
       "1           0           0           0         0         0.41  \n",
       "2           0           0           0         0         5.49  \n",
       "3           0           1           0         0        22.47  \n",
       "4           1           0           0         0         1.43  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape, df.is_blocked.mean())\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://kaggle2.blob.core.windows.net/competitions/kaggle/3929/media/Ad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio 0.228222107326\n",
      "Count: 1204949\n"
     ]
    }
   ],
   "source": [
    "print(\"Blocked ratio\",df.is_blocked.mean())\n",
    "print(\"Count:\",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance-out the classes\n",
    "* Vast majority of data samples are non-prohibited\n",
    " * 250k banned out of 4kk\n",
    " * Let's just downsample random 250k legal samples to make further steps less computationally demanding\n",
    " * If you aim for high Kaggle score, consider a smarter approach to that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio: 0.499992727273\n",
      "Count: 550000\n"
     ]
    }
   ],
   "source": [
    "#downsample\n",
    "\n",
    "ddf = df.sort_values(by=\"is_blocked\",ascending=False) # sort by is_blocked\n",
    "ddf2 = ddf[:550000] \n",
    "# < downsample data so that both classes have approximately equal ratios>\n",
    "\n",
    "df = ddf2\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Blocked ratio:\",df.is_blocked.mean())\n",
    "print(\"Count:\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "assert df.is_blocked.mean() < 0.51\n",
    "assert df.is_blocked.mean() > 0.49\n",
    "assert len(df) <= 560000\n",
    "\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'very_low_ram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7cd356d2aa3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#In case your RAM-o-meter is in the red\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mvery_low_ram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'very_low_ram' is not defined"
     ]
    }
   ],
   "source": [
    "#In case your RAM-o-meter is in the red\n",
    "if very_low_ram:\n",
    "    data = data[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing\n",
    "\n",
    "First, we create a dictionary of all existing words.\n",
    "Assign each word a number - it's Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter,defaultdict\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "#Dictionary of tokens\n",
    "token_counts = Counter()\n",
    "\n",
    "#All texts\n",
    "all_texts = np.hstack([df.description.values,df.title.values])\n",
    "\n",
    "\n",
    "#Compute token frequencies\n",
    "for s in all_texts:\n",
    "    if type(s) is not str:\n",
    "        continue\n",
    "    s = s.lower()\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    for token in tokens:\n",
    "        token_counts[token] +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare tokens\n",
    "\n",
    "We are unlikely to make use of words that are only seen a few times throughout the corpora.\n",
    "\n",
    "Again, if you want to beat Kaggle competition metrics, consider doing something better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNCRJ3f4X0ZenC1wukEUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x136317a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Word frequency distribution, just for kicks\n",
    "_=plt.hist(list(token_counts.values()),range=[0,50],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'квартира': 86510,\n",
       "         'улучшенной': 855,\n",
       "         'планировки': 2274,\n",
       "         'лоджия': 7365,\n",
       "         '6': 41302,\n",
       "         'м': 54913,\n",
       "         'застеклена': 1904,\n",
       "         'большая': 5662,\n",
       "         'кухня': 13938,\n",
       "         'комнаты': 10633,\n",
       "         'изолированные': 2007,\n",
       "         'на': 373617,\n",
       "         'кухне': 2268,\n",
       "         'в': 594138,\n",
       "         'зале': 585,\n",
       "         'и': 573780,\n",
       "         'коридоре': 559,\n",
       "         'сделан': 3375,\n",
       "         'хороший': 7838,\n",
       "         'ремонт': 26560,\n",
       "         'выровнены': 328,\n",
       "         'стены': 2673,\n",
       "         'натяжные': 1471,\n",
       "         'потолки': 3532,\n",
       "         'пол': 4571,\n",
       "         'кафель': 2922,\n",
       "         'ламинат': 3720,\n",
       "         'остальных': 293,\n",
       "         'комнатах': 771,\n",
       "         'линолеум': 1512,\n",
       "         'во': 14944,\n",
       "         'всех': 12059,\n",
       "         'пластиковые': 6490,\n",
       "         'окна': 15788,\n",
       "         'электропроводка': 420,\n",
       "         'заменена': 533,\n",
       "         'полностью': 10429,\n",
       "         'ванной': 1444,\n",
       "         'новая': 18678,\n",
       "         'сантехника': 3269,\n",
       "         'остается': 2558,\n",
       "         'шкаф': 5803,\n",
       "         'купе': 2747,\n",
       "         'встроенная': 3818,\n",
       "         'p': 1405615,\n",
       "         '62': 2445,\n",
       "         '777': 480,\n",
       "         '8': 81662,\n",
       "         'phone': 66010,\n",
       "         'выбираете': 179,\n",
       "         'автомобиль': 10940,\n",
       "         'боитесь': 52,\n",
       "         'купить': 3899,\n",
       "         'кота': 386,\n",
       "         'мешке': 33,\n",
       "         'звоните': 28587,\n",
       "         'помогаем': 660,\n",
       "         'выбрать': 997,\n",
       "         'авто': 15775,\n",
       "         'с': 290545,\n",
       "         'пробегом': 517,\n",
       "         'том': 5307,\n",
       "         'числе': 3278,\n",
       "         'газели': 342,\n",
       "         'проверяем': 88,\n",
       "         'наличие': 4866,\n",
       "         'скрытых': 432,\n",
       "         'кузовных': 59,\n",
       "         'дефектов': 1388,\n",
       "         'покрасов': 9,\n",
       "         'агрегатов': 98,\n",
       "         'юридическое': 867,\n",
       "         'сопровождение': 3766,\n",
       "         'сделки': 1595,\n",
       "         'оформление': 8093,\n",
       "         'договоров': 1410,\n",
       "         'купли': 1351,\n",
       "         'продажи': 5404,\n",
       "         'страховки': 316,\n",
       "         'помощь': 34211,\n",
       "         'оформлением': 528,\n",
       "         'гибдд': 792,\n",
       "         'проверка': 2214,\n",
       "         'автомобиля': 5699,\n",
       "         'органах': 410,\n",
       "         'выезд': 11020,\n",
       "         'специалиста': 1871,\n",
       "         'место': 8211,\n",
       "         'всего': 12719,\n",
       "         '500': 15536,\n",
       "         'рублей': 33425,\n",
       "         'работаем': 4824,\n",
       "         'без': 80238,\n",
       "         'выходных': 2053,\n",
       "         'а': 38461,\n",
       "         'также': 22520,\n",
       "         'разрешаем': 4,\n",
       "         'споры': 208,\n",
       "         'касающиеся': 32,\n",
       "         'оформления': 1576,\n",
       "         'транспортных': 566,\n",
       "         'средств': 2293,\n",
       "         'прав': 863,\n",
       "         'наследия': 30,\n",
       "         'ареста': 20,\n",
       "         'залога': 618,\n",
       "         'спорных': 49,\n",
       "         'вопросов': 1157,\n",
       "         'со': 19595,\n",
       "         'страховой': 865,\n",
       "         'возмещение': 71,\n",
       "         'убытков': 57,\n",
       "         'консультации': 7168,\n",
       "         'представительство': 322,\n",
       "         'суде': 304,\n",
       "         'иных': 289,\n",
       "         'инстанциях': 17,\n",
       "         'опыт': 17814,\n",
       "         'работы': 60067,\n",
       "         'рынке': 1734,\n",
       "         '16': 17818,\n",
       "         'лет': 30451,\n",
       "         'демисезонная': 170,\n",
       "         'плюс': 3176,\n",
       "         'к': 126221,\n",
       "         'ней': 1817,\n",
       "         'отдам': 10630,\n",
       "         'штаны': 875,\n",
       "         'комплект': 17946,\n",
       "         'новый': 31511,\n",
       "         'кальян': 7900,\n",
       "         'ни': 5524,\n",
       "         'разу': 1881,\n",
       "         'не': 155207,\n",
       "         'использовался': 2540,\n",
       "         'состояние': 42118,\n",
       "         'идеальное': 4442,\n",
       "         'упаковке': 4564,\n",
       "         'g': 1969,\n",
       "         '36c': 9,\n",
       "         'артикул': 758,\n",
       "         'ge': 81,\n",
       "         '0636iii': 1,\n",
       "         'автомат': 4335,\n",
       "         'коробочке': 164,\n",
       "         'прайс': 685,\n",
       "         'лист': 1419,\n",
       "         'март': 427,\n",
       "         '2014': 7626,\n",
       "         'название': 858,\n",
       "         'мрц': 229,\n",
       "         'базовая': 351,\n",
       "         'цена': 46861,\n",
       "         'бц': 173,\n",
       "         'от': 118412,\n",
       "         'руб': 67958,\n",
       "         'пачка': 1298,\n",
       "         '1': 138873,\n",
       "         'бонд': 80,\n",
       "         'стрит': 32,\n",
       "         'лайт': 239,\n",
       "         'пачке': 284,\n",
       "         '44': 6625,\n",
       "         'опт': 1141,\n",
       "         'цен': 490,\n",
       "         '40': 16229,\n",
       "         '2': 155037,\n",
       "         'винстон': 198,\n",
       "         '54': 3791,\n",
       "         '47': 2762,\n",
       "         '3': 105612,\n",
       "         'донской': 137,\n",
       "         'табак': 2242,\n",
       "         'тёмный': 73,\n",
       "         '35': 7708,\n",
       "         '31': 4551,\n",
       "         '5': 104786,\n",
       "         '4': 71828,\n",
       "         'лм': 147,\n",
       "         'синий': 1792,\n",
       "         '42': 6313,\n",
       "         'красный': 1980,\n",
       "         'мальборо': 152,\n",
       "         'белый': 4440,\n",
       "         '74': 2125,\n",
       "         '60': 13756,\n",
       "         '7': 37497,\n",
       "         'парламент': 216,\n",
       "         '86': 1567,\n",
       "         '73': 1104,\n",
       "         '9': 41997,\n",
       "         'прима': 90,\n",
       "         'дона': 38,\n",
       "         '29': 3036,\n",
       "         '23': 6355,\n",
       "         '10': 56324,\n",
       "         'св': 488,\n",
       "         'георгий': 158,\n",
       "         '37': 4025,\n",
       "         '33': 3999,\n",
       "         '11': 12028,\n",
       "         '12': 24003,\n",
       "         'тройка': 178,\n",
       "         '32': 6768,\n",
       "         '13': 11083,\n",
       "         'честрилд': 4,\n",
       "         '55': 6403,\n",
       "         'продам': 83710,\n",
       "         'платья': 1046,\n",
       "         'одеты': 245,\n",
       "         'один': 17494,\n",
       "         'раз': 8207,\n",
       "         'до': 77988,\n",
       "         '1000': 10857,\n",
       "         'удоставерение': 21,\n",
       "         'ветерана': 78,\n",
       "         'боевых': 253,\n",
       "         'действий': 420,\n",
       "         'срочно': 19111,\n",
       "         'через': 10697,\n",
       "         'юриста': 280,\n",
       "         'переоформлением': 167,\n",
       "         'ваше': 2863,\n",
       "         'имя': 1091,\n",
       "         'пожизненная': 87,\n",
       "         'пенсия': 40,\n",
       "         'льготы': 62,\n",
       "         'права': 2301,\n",
       "         'получить': 4635,\n",
       "         'земельный': 2328,\n",
       "         'участок': 12822,\n",
       "         'любое': 7770,\n",
       "         'время': 24149,\n",
       "         '700000т': 8,\n",
       "         'продается': 20248,\n",
       "         'дом': 42551,\n",
       "         'крыша': 1303,\n",
       "         'профиль': 579,\n",
       "         'мпо': 758,\n",
       "         'дверь': 6639,\n",
       "         'металлическая': 2429,\n",
       "         'документы': 15816,\n",
       "         'район': 10079,\n",
       "         'развитой': 1062,\n",
       "         'инфраструктурой': 1288,\n",
       "         'магазины': 6475,\n",
       "         'остановка': 3970,\n",
       "         'школа': 7313,\n",
       "         'садик': 1451,\n",
       "         'тел': 19602,\n",
       "         'фото': 16160,\n",
       "         'реальный': 1435,\n",
       "         'объект': 1228,\n",
       "         'акустика': 352,\n",
       "         'известной': 265,\n",
       "         'прошлом': 369,\n",
       "         'компании': 7209,\n",
       "         'celestion': 10,\n",
       "         'трехполосные': 3,\n",
       "         'полочники': 6,\n",
       "         'фазоинвертором': 5,\n",
       "         'направленным': 12,\n",
       "         'под': 28961,\n",
       "         'углом': 159,\n",
       "         'который': 7088,\n",
       "         'находится': 6403,\n",
       "         'задней': 1165,\n",
       "         'стенке': 88,\n",
       "         'сборка': 1996,\n",
       "         'англия': 286,\n",
       "         'отличном': 21820,\n",
       "         'техническом': 876,\n",
       "         'косметическом': 69,\n",
       "         'состоянии': 52537,\n",
       "         'крайне': 479,\n",
       "         'редкая': 222,\n",
       "         'эта': 1659,\n",
       "         'линейка': 183,\n",
       "         '90': 5985,\n",
       "         'х': 27091,\n",
       "         'впечатлила': 2,\n",
       "         'западную': 13,\n",
       "         'прессу': 5,\n",
       "         'своим': 2030,\n",
       "         'звучанием': 31,\n",
       "         'относительно': 355,\n",
       "         'небольшой': 3395,\n",
       "         'ценой': 217,\n",
       "         'сцена': 22,\n",
       "         'однородна': 1,\n",
       "         'чувствительность': 559,\n",
       "         'достаточная': 9,\n",
       "         'что': 30457,\n",
       "         'б': 17451,\n",
       "         'их': 7708,\n",
       "         'подключить': 300,\n",
       "         'ламповому': 3,\n",
       "         'усилителю': 19,\n",
       "         'комната': 12462,\n",
       "         'балконом': 718,\n",
       "         'балкон': 8346,\n",
       "         'застеклен': 2340,\n",
       "         'сан': 3323,\n",
       "         'узел': 2607,\n",
       "         'общий': 8103,\n",
       "         'чисто': 962,\n",
       "         'аккуратно': 993,\n",
       "         'горящее': 8,\n",
       "         'предложение': 3057,\n",
       "         'долгосрочный': 91,\n",
       "         'период': 1950,\n",
       "         'сдается': 6794,\n",
       "         'чистенькая': 98,\n",
       "         'квартире': 8414,\n",
       "         'есть': 58011,\n",
       "         'все': 84468,\n",
       "         'необходимое': 1991,\n",
       "         'для': 178965,\n",
       "         'проживания': 3871,\n",
       "         'холодильник': 7643,\n",
       "         'телевизор': 5289,\n",
       "         'стиральная': 4473,\n",
       "         'машина': 12504,\n",
       "         'нормальное': 828,\n",
       "         'проведен': 467,\n",
       "         'интернет': 13336,\n",
       "         'кабельное': 1127,\n",
       "         'телевидение': 887,\n",
       "         'вид': 7197,\n",
       "         'из': 68632,\n",
       "         'спокойные': 338,\n",
       "         'соседи': 3045,\n",
       "         'хозяева': 302,\n",
       "         'город': 3981,\n",
       "         'приезжают': 20,\n",
       "         'только': 29373,\n",
       "         'за': 81035,\n",
       "         'оплатой': 402,\n",
       "         'возьмут': 24,\n",
       "         'приличных': 181,\n",
       "         'людей': 4192,\n",
       "         'просмотр': 849,\n",
       "         'по': 224460,\n",
       "         'согласованию': 184,\n",
       "         'агент': 1358,\n",
       "         'агентства': 765,\n",
       "         'просьба': 4535,\n",
       "         'звонить': 11073,\n",
       "         'более': 20096,\n",
       "         'подробную': 1961,\n",
       "         'информацию': 4296,\n",
       "         'об': 3443,\n",
       "         'объекте': 225,\n",
       "         'можно': 32195,\n",
       "         'узнать': 2261,\n",
       "         'нашем': 18734,\n",
       "         'сайте': 7621,\n",
       "         'ссылке': 2803,\n",
       "         'url': 20154,\n",
       "         'выбирая': 62,\n",
       "         'abrecafe': 71,\n",
       "         'вы': 29702,\n",
       "         'выполняете': 19,\n",
       "         'четыре': 1267,\n",
       "         'задачи': 2077,\n",
       "         'одновременно': 973,\n",
       "         'снижаете': 9,\n",
       "         'лишний': 433,\n",
       "         'вес': 12059,\n",
       "         'стимулируете': 5,\n",
       "         'деятельность': 1039,\n",
       "         'тела': 8895,\n",
       "         'повышаете': 7,\n",
       "         'активность': 741,\n",
       "         'клеток': 1141,\n",
       "         'головного': 473,\n",
       "         'мозга': 750,\n",
       "         'наслаждаетесь': 21,\n",
       "         'природным': 153,\n",
       "         'вкусом': 618,\n",
       "         'редкого': 116,\n",
       "         'сорта': 320,\n",
       "         'кофеснижение': 1,\n",
       "         'веса': 3229,\n",
       "         'абрекафе': 38,\n",
       "         'этот': 4255,\n",
       "         'продукт': 2121,\n",
       "         'уже': 7935,\n",
       "         'известен': 168,\n",
       "         'нашим': 648,\n",
       "         'постоянным': 942,\n",
       "         'покупателям': 615,\n",
       "         'обладает': 2444,\n",
       "         'удивительными': 41,\n",
       "         'свойствами': 587,\n",
       "         'натурального': 824,\n",
       "         'зеленого': 828,\n",
       "         'кофе': 5748,\n",
       "         'похудения': 3246,\n",
       "         'как': 34331,\n",
       "         'же': 19764,\n",
       "         'способствует': 3102,\n",
       "         'похудению': 175,\n",
       "         'причиной': 147,\n",
       "         'излишнего': 36,\n",
       "         'зачастую': 174,\n",
       "         'является': 7404,\n",
       "         'правильное': 307,\n",
       "         'питание': 4887,\n",
       "         'или': 52768,\n",
       "         'переедание': 31,\n",
       "         'многие': 1669,\n",
       "         'люди': 2804,\n",
       "         'это': 25358,\n",
       "         'понимают': 84,\n",
       "         'но': 19141,\n",
       "         'могут': 2202,\n",
       "         'справиться': 589,\n",
       "         'этими': 127,\n",
       "         'проблемами': 504,\n",
       "         'самостоятельно': 1355,\n",
       "         'натуральный': 2575,\n",
       "         'зеленый': 3807,\n",
       "         'хлорогеновая': 132,\n",
       "         'кислота': 1004,\n",
       "         'одним': 1567,\n",
       "         'натуральных': 874,\n",
       "         'природных': 246,\n",
       "         'компонентов': 931,\n",
       "         'заставляющих': 14,\n",
       "         'организм': 2296,\n",
       "         'человека': 5485,\n",
       "         'сжигать': 71,\n",
       "         'жиры': 392,\n",
       "         'вместо': 1688,\n",
       "         'углеводов': 288,\n",
       "         'при': 46462,\n",
       "         'вырабатывании': 15,\n",
       "         'энергии': 2122,\n",
       "         'согласно': 1336,\n",
       "         'результатам': 473,\n",
       "         'проведенного': 38,\n",
       "         'исследования': 602,\n",
       "         'содержит': 2161,\n",
       "         'хлорогеновой': 156,\n",
       "         'кислоты': 983,\n",
       "         'счет': 3927,\n",
       "         'этого': 4300,\n",
       "         'отбивает': 69,\n",
       "         'чрезмерный': 23,\n",
       "         'аппетит': 497,\n",
       "         'человек': 4082,\n",
       "         'быстрее': 517,\n",
       "         'насыщается': 29,\n",
       "         'почему': 988,\n",
       "         'именно': 2957,\n",
       "         'если': 19545,\n",
       "         'преследуете': 1,\n",
       "         'цель': 707,\n",
       "         'похудеть': 818,\n",
       "         'вреда': 379,\n",
       "         'здоровья': 4711,\n",
       "         'тогда': 1321,\n",
       "         'нужно': 6140,\n",
       "         'внимательно': 554,\n",
       "         'относиться': 42,\n",
       "         'тому': 840,\n",
       "         'употребляете': 14,\n",
       "         'перед': 3675,\n",
       "         'нами': 1088,\n",
       "         'встала': 5,\n",
       "         'задача': 491,\n",
       "         'необработанных': 5,\n",
       "         'зеленых': 142,\n",
       "         'зерен': 99,\n",
       "         'содержащих': 59,\n",
       "         'хлорогеновую': 12,\n",
       "         'кислоту': 109,\n",
       "         'вывести': 183,\n",
       "         'вредные': 260,\n",
       "         'вещества': 930,\n",
       "         'этом': 5418,\n",
       "         'сохранить': 512,\n",
       "         'максимальное': 770,\n",
       "         'содержание': 961,\n",
       "         'каждом': 780,\n",
       "         'зерне': 11,\n",
       "         'того': 4335,\n",
       "         'чтобы': 5526,\n",
       "         'зерна': 258,\n",
       "         'влияли': 1,\n",
       "         'исключительно': 1077,\n",
       "         'положительно': 224,\n",
       "         'необходимо': 2726,\n",
       "         'подвергнуть': 3,\n",
       "         'термической': 27,\n",
       "         'обработке': 247,\n",
       "         'после': 21528,\n",
       "         'такой': 2400,\n",
       "         'обработки': 489,\n",
       "         'выводятся': 119,\n",
       "         'было': 2712,\n",
       "         'сказано': 43,\n",
       "         'выше': 2200,\n",
       "         'содержится': 339,\n",
       "         'около': 5623,\n",
       "         'так': 29828,\n",
       "         'вот': 2258,\n",
       "         'вам': 25384,\n",
       "         'обжаривать': 6,\n",
       "         'готов': 2095,\n",
       "         'употреблению': 81,\n",
       "         'эффективен': 413,\n",
       "         'безопасен': 222,\n",
       "         'подтверждено': 68,\n",
       "         'независимыми': 25,\n",
       "         'испытаниями': 17,\n",
       "         'полезные': 466,\n",
       "         'свойства': 1081,\n",
       "         'термически': 17,\n",
       "         'обработанного': 11,\n",
       "         'помимо': 858,\n",
       "         'уменьшает': 689,\n",
       "         'риск': 399,\n",
       "         'переедания': 24,\n",
       "         'он': 8576,\n",
       "         'рядом': 17140,\n",
       "         'других': 5681,\n",
       "         'интересных': 192,\n",
       "         'полезных': 471,\n",
       "         'свойств': 323,\n",
       "         'стимулирование': 99,\n",
       "         'двигательной': 165,\n",
       "         'активности': 384,\n",
       "         'повышает': 1863,\n",
       "         'двигательную': 58,\n",
       "         'высокого': 1460,\n",
       "         'содержания': 464,\n",
       "         'природного': 149,\n",
       "         'кофеина': 124,\n",
       "         'являющегося': 18,\n",
       "         'натуральной': 1229,\n",
       "         'составляющей': 49,\n",
       "         'продукта': 1139,\n",
       "         'начинает': 476,\n",
       "         'чувствовать': 492,\n",
       "         'себя': 9939,\n",
       "         'бодро': 48,\n",
       "         'выполнять': 440,\n",
       "         'больше': 5584,\n",
       "         'дел': 419,\n",
       "         'становится': 902,\n",
       "         'способен': 573,\n",
       "         'произвести': 263,\n",
       "         'физических': 1039,\n",
       "         'нагрузок': 373,\n",
       "         'человеку': 890,\n",
       "         'употребляющему': 1,\n",
       "         'гораздо': 555,\n",
       "         'проще': 243,\n",
       "         'начать': 579,\n",
       "         'заниматься': 654,\n",
       "         'спортом': 496,\n",
       "         'этим': 1127,\n",
       "         'занимался': 72,\n",
       "         'повышение': 1328,\n",
       "         'умственных': 77,\n",
       "         'способностей': 309,\n",
       "         'деятельности': 2864,\n",
       "         'происходит': 1828,\n",
       "         'благодаря': 3843,\n",
       "         'танину': 11,\n",
       "         'ещё': 1950,\n",
       "         'одному': 436,\n",
       "         'натуральному': 38,\n",
       "         'компоненту': 10,\n",
       "         'стоит': 6435,\n",
       "         'обратить': 120,\n",
       "         'противопоказания': 877,\n",
       "         'прежде': 442,\n",
       "         'чем': 5803,\n",
       "         'пить': 413,\n",
       "         'рекомендуется': 1175,\n",
       "         'гипертонии': 210,\n",
       "         'нарушении': 221,\n",
       "         'сердечной': 115,\n",
       "         'беременность': 404,\n",
       "         'индивидуальной': 571,\n",
       "         'непереносимости': 52,\n",
       "         'женщинам': 1023,\n",
       "         'кормящим': 106,\n",
       "         'грудью': 264,\n",
       "         'вещи': 1923,\n",
       "         'фирменные': 355,\n",
       "         'хорошем': 22017,\n",
       "         'продаю': 42805,\n",
       "         'пакетом': 549,\n",
       "         'стоимость': 13806,\n",
       "         'вещичек': 13,\n",
       "         '500р': 3334,\n",
       "         'восстановление': 3994,\n",
       "         'энергетики': 182,\n",
       "         'преображение': 26,\n",
       "         'будущего': 354,\n",
       "         'снятие': 2997,\n",
       "         'негатива': 166,\n",
       "         'смотрим': 71,\n",
       "         'спа': 2141,\n",
       "         'программы': 4575,\n",
       "         'выходя': 469,\n",
       "         'дома': 19966,\n",
       "         'уникальное': 576,\n",
       "         'супер': 2185,\n",
       "         'программам': 236,\n",
       "         'массажу': 1865,\n",
       "         'возрастов': 213,\n",
       "         'скраб': 297,\n",
       "         'гидромассаж': 93,\n",
       "         'антицеллюлитный': 10755,\n",
       "         'массаж': 86264,\n",
       "         'оздоровительный': 4448,\n",
       "         'гуаша': 402,\n",
       "         'антицеллюлитное': 236,\n",
       "         'шоколадное': 713,\n",
       "         'обертывание': 2352,\n",
       "         'завершение': 48,\n",
       "         'потрясающий': 213,\n",
       "         'крем': 1490,\n",
       "         'телу': 1037,\n",
       "         'вытяжкой': 58,\n",
       "         'икры': 218,\n",
       "         'лососевых': 57,\n",
       "         'процедуры': 4917,\n",
       "         'провожу': 1485,\n",
       "         'лично': 1424,\n",
       "         'профессиональный': 5289,\n",
       "         'стаж': 4219,\n",
       "         '1992': 798,\n",
       "         'года': 24373,\n",
       "         'вдумайтесь': 3,\n",
       "         'эти': 1894,\n",
       "         'цифры': 605,\n",
       "         '22': 8093,\n",
       "         'тысячи': 672,\n",
       "         'благодарных': 61,\n",
       "         'клиентов': 3862,\n",
       "         'такого': 983,\n",
       "         'еще': 7782,\n",
       "         'пробовали': 36,\n",
       "         'упустите': 245,\n",
       "         'шанс': 497,\n",
       "         'шикарную': 94,\n",
       "         'процедуру': 856,\n",
       "         'своего': 2270,\n",
       "         'kpeдит': 1017,\n",
       "         'чеpез': 1226,\n",
       "         'интеpнeт': 1219,\n",
       "         'справок': 3157,\n",
       "         'поручителей': 3025,\n",
       "         'владивосток': 165,\n",
       "         'пoлyчитe': 623,\n",
       "         'кpедит': 3415,\n",
       "         'зa': 7441,\n",
       "         'нecкoлько': 575,\n",
       "         'минут': 16299,\n",
       "         'одобряются': 6422,\n",
       "         'бeз': 9937,\n",
       "         '000': 23701,\n",
       "         'pyб': 1705,\n",
       "         'выдачa': 904,\n",
       "         'кpедитa': 930,\n",
       "         'день': 16519,\n",
       "         'oдобрeние': 225,\n",
       "         'посeщения': 942,\n",
       "         'офиса': 1876,\n",
       "         'бaнка': 1843,\n",
       "         'пpоверки': 911,\n",
       "         'кpeдитной': 919,\n",
       "         'истoрии': 976,\n",
       "         'oзнакомиться': 533,\n",
       "         'c': 9293,\n",
       "         'yслoвиями': 910,\n",
       "         'оcтавить': 473,\n",
       "         'заявку': 2836,\n",
       "         'мoжнo': 1891,\n",
       "         'caйте': 1269,\n",
       "         'kод': 1837,\n",
       "         'oбъявления': 1777,\n",
       "         '91821270': 1,\n",
       "         'виды': 11741,\n",
       "         'компьютерной': 450,\n",
       "         'помощи': 3501,\n",
       "         'запрещенные': 6,\n",
       "         'ук': 104,\n",
       "         'рф': 10313,\n",
       "         'всем': 10746,\n",
       "         'вопросам': 5568,\n",
       "         'почту': 8009,\n",
       "         'мне': 7267,\n",
       "         '19лет': 24,\n",
       "         'рост': 4938,\n",
       "         '168': 188,\n",
       "         '45': 9779,\n",
       "         'блондинка': 49,\n",
       "         'ищу': 9198,\n",
       "         'парня': 433,\n",
       "         '20': 24283,\n",
       "         '26': 3753,\n",
       "         'серьезные': 168,\n",
       "         'отношения': 1498,\n",
       "         'нерусские': 3,\n",
       "         'судимые': 12,\n",
       "         'беспокоить': 3460,\n",
       "         'т': 31691,\n",
       "         'комнатную': 4483,\n",
       "         'квартиру': 19458,\n",
       "         'солнечном': 58,\n",
       "         'этаж': 8632,\n",
       "         'этажном': 443,\n",
       "         'панельном': 212,\n",
       "         'доме': 10592,\n",
       "         '18': 16423,\n",
       "         '50': 21356,\n",
       "         'спальня': 913,\n",
       "         '70': 9082,\n",
       "         'большой': 11618,\n",
       "         'комнате': 2616,\n",
       "         '0': 21942,\n",
       "         'кв': 32860,\n",
       "         'деревянные': 1227,\n",
       "         'туалет': 1942,\n",
       "         'кафеля': 117,\n",
       "         'снимаю': 405,\n",
       "         'порчу': 366,\n",
       "         'опухоль': 66,\n",
       "         'сглаз': 307,\n",
       "         'восстанавливаю': 47,\n",
       "         'ауру': 58,\n",
       "         'предсказание': 199,\n",
       "         'точное': 160,\n",
       "         'прошлого': 325,\n",
       "         'недорого': 8358,\n",
       "         'валентина': 258,\n",
       "         'новостройка': 485,\n",
       "         '80м': 66,\n",
       "         'евроремонт': 1716,\n",
       "         'частично': 1951,\n",
       "         'мебелезирована': 3,\n",
       "         'советских': 103,\n",
       "         'времён': 106,\n",
       "         'нетронутая': 9,\n",
       "         'превосходный': 199,\n",
       "         'подарок': 15125,\n",
       "         'новому': 911,\n",
       "         'году': 3665,\n",
       "         'у': 56172,\n",
       "         'вас': 25455,\n",
       "         'появилась': 223,\n",
       "         'возможность': 9742,\n",
       "         'преобрести': 85,\n",
       "         'легендаоный': 1,\n",
       "         'арбалет': 2196,\n",
       "         'сравнитель': 1,\n",
       "         'цене': 5155,\n",
       "         'ведь': 1317,\n",
       "         'оно': 1025,\n",
       "         'математика': 2380,\n",
       "         'информатика': 585,\n",
       "         'программирование': 493,\n",
       "         'delphi': 122,\n",
       "         'pascal': 195,\n",
       "         'упаковка': 3493,\n",
       "         '250': 6324,\n",
       "         'гр': 4567,\n",
       "         'заказывала': 279,\n",
       "         'пока': 2267,\n",
       "         'шел': 45,\n",
       "         'заказ': 7949,\n",
       "         'узнала': 27,\n",
       "         'беременна': 28,\n",
       "         'поэтому': 4466,\n",
       "         'покупала': 2006,\n",
       "         'сдам': 10111,\n",
       "         'новогодний': 599,\n",
       "         'ассортмент': 1,\n",
       "         'площадь': 11316,\n",
       "         'трц': 353,\n",
       "         'июнь': 323,\n",
       "         'новой': 2692,\n",
       "         'усмани': 8,\n",
       "         'р': 39301,\n",
       "         'н': 4734,\n",
       "         'пчелка': 57,\n",
       "         'кадастровый': 171,\n",
       "         'номер': 10525,\n",
       "         '36': 5057,\n",
       "         '0101007': 1,\n",
       "         '788': 11,\n",
       "         'смотреть': 1070,\n",
       "         'публичной': 48,\n",
       "         'кадастровой': 34,\n",
       "         'карте': 446,\n",
       "         'интернете': 2262,\n",
       "         'номеру': 1516,\n",
       "         'адрес': 4090,\n",
       "         'усмань': 32,\n",
       "         'ул': 20366,\n",
       "         'потемкина': 2,\n",
       "         'торг': 35533,\n",
       "         'контрольные': 13027,\n",
       "         'выполнением': 259,\n",
       "         'домашнего': 882,\n",
       "         'задания': 1919,\n",
       "         'перевод': 1796,\n",
       "         'требуется': 10759,\n",
       "         'повар': 499,\n",
       "         'универсал': 937,\n",
       "         'любящий': 31,\n",
       "         'свою': 3053,\n",
       "         'работу': 15504,\n",
       "         'хорошее': 13184,\n",
       "         'отношение': 787,\n",
       "         'работе': 5295,\n",
       "         'нас': 6265,\n",
       "         'достойная': 402,\n",
       "         'заработная': 1021,\n",
       "         'плата': 2680,\n",
       "         'перспективой': 70,\n",
       "         'ее': 3970,\n",
       "         'роста': 2321,\n",
       "         'повышения': 935,\n",
       "         'должности': 636,\n",
       "         'систематизировать': 12,\n",
       "         'кухню': 436,\n",
       "         'сделать': 3914,\n",
       "         'вкусно': 224,\n",
       "         'сказать': 619,\n",
       "         'работа': 18655,\n",
       "         'нуля': 365,\n",
       "         'определённые': 21,\n",
       "         'наработки': 74,\n",
       "         'абсолютно': 5417,\n",
       "         'египта': 343,\n",
       "         '64': 3082,\n",
       "         'cм': 133,\n",
       "         'двухтрубчатый': 7,\n",
       "         'крeдит': 3360,\n",
       "         'чеpeз': 1228,\n",
       "         'cправок': 2224,\n",
       "         'поручителeй': 2142,\n",
       "         'миасс': 128,\n",
       "         'офоpмите': 468,\n",
       "         'нeскoлько': 564,\n",
       "         'дo': 5995,\n",
       "         'pуб': 1790,\n",
       "         'bыдачa': 909,\n",
       "         'oдобpение': 240,\n",
       "         'пoсeщения': 940,\n",
       "         'oфиса': 879,\n",
       "         'банкa': 1844,\n",
       "         'пpовеpки': 902,\n",
       "         'кpeдитнoй': 947,\n",
       "         'истopии': 846,\n",
       "         'oзнакомитьcя': 471,\n",
       "         'oставить': 479,\n",
       "         'зaявкy': 1799,\n",
       "         'можнo': 1856,\n",
       "         'cайтe': 1188,\n",
       "         'объявления': 2791,\n",
       "         'калмия': 1,\n",
       "         '80': 8008,\n",
       "         'п': 10710,\n",
       "         'шильна': 7,\n",
       "         'соток': 4265,\n",
       "         '450': 2258,\n",
       "         '000р': 1291,\n",
       "         'ижс': 3695,\n",
       "         'собственности': 4331,\n",
       "         'продолжение': 91,\n",
       "         'проспекта': 315,\n",
       "         'мира': 1544,\n",
       "         'электричество': 2716,\n",
       "         'проводят': 212,\n",
       "         'остальные': 1479,\n",
       "         'улицы': 1233,\n",
       "         'коммуникации': 4024,\n",
       "         'федеральной': 225,\n",
       "         'программе': 1330,\n",
       "         'газ': 8794,\n",
       "         '2015г': 461,\n",
       "         '28': 4342,\n",
       "         'малая': 208,\n",
       "         '430': 301,\n",
       "         '680': 196,\n",
       "         '750': 1669,\n",
       "         '000руб': 394,\n",
       "         'рябинка': 8,\n",
       "         '300000р': 20,\n",
       "         'земля': 1009,\n",
       "         '2013г': 1589,\n",
       "         'км': 9492,\n",
       "         'города': 11031,\n",
       "         'кырныш': 2,\n",
       "         'учасок': 7,\n",
       "         '110000р': 4,\n",
       "         'ясной': 19,\n",
       "         'поляны': 47,\n",
       "         'дачное': 73,\n",
       "         'назначение': 1327,\n",
       "         'лес': 1750,\n",
       "         'кама': 514,\n",
       "         '140': 2069,\n",
       "         'районе': 10210,\n",
       "         'новое': 6077,\n",
       "         'здание': 1752,\n",
       "         '3164': 5,\n",
       "         'участке': 11158,\n",
       "         '06': 1324,\n",
       "         'га': 1045,\n",
       "         'застройки': 458,\n",
       "         '375': 156,\n",
       "         'договор': 2579,\n",
       "         'долгосрочной': 57,\n",
       "         'аренды': 1426,\n",
       "         'участка': 2731,\n",
       "         '2008': 6454,\n",
       "         'г': 32669,\n",
       "         '2032': 4,\n",
       "         'высокие': 1242,\n",
       "         'самые': 2436,\n",
       "         'современный': 1709,\n",
       "         'инженерные': 295,\n",
       "         'системы': 6457,\n",
       "         'оптико': 37,\n",
       "         'волоконная': 16,\n",
       "         'связь': 1828,\n",
       "         'подземная': 337,\n",
       "         'двухуровневая': 107,\n",
       "         'парковка': 2910,\n",
       "         '24': 7599,\n",
       "         'машины': 3090,\n",
       "         'свободная': 927,\n",
       "         'планировка': 2909,\n",
       "         'scell': 1,\n",
       "         'core': 1669,\n",
       "         'электроснабжение': 290,\n",
       "         '215': 1749,\n",
       "         'ква': 60,\n",
       "         'наставнический': 4,\n",
       "         'переулок': 199,\n",
       "         'базе': 12917,\n",
       "         '13191': 1,\n",
       "         'мужчин': 2664,\n",
       "         'специальная': 484,\n",
       "         'техника': 9411,\n",
       "         'глубокого': 194,\n",
       "         'расслабления': 387,\n",
       "         'помогает': 2547,\n",
       "         'отдохнуть': 508,\n",
       "         'восстановиться': 91,\n",
       "         'воздействует': 290,\n",
       "         'энергетику': 120,\n",
       "         'душевное': 106,\n",
       "         'равновесие': 172,\n",
       "         'индивидуальный': 5360,\n",
       "         'подход': 5352,\n",
       "         'каждому': 3108,\n",
       "         'сделаю': 1846,\n",
       "         'английскому': 2785,\n",
       "         'немецкому': 685,\n",
       "         'языку': 3234,\n",
       "         'мебели': 3846,\n",
       "         'длительный': 5959,\n",
       "         'срок': 16482,\n",
       "         'классический': 12083,\n",
       "         'детский': 12371,\n",
       "         'жилая': 2431,\n",
       "         'пластик': 3268,\n",
       "         'тыс': 7013,\n",
       "         'блок': 4326,\n",
       "         'розжига': 111,\n",
       "         'hid': 25,\n",
       "         'пластиковый': 524,\n",
       "         'тонкий': 440,\n",
       "         '16v': 166,\n",
       "         'ксенона': 77,\n",
       "         'гарантия': 9662,\n",
       "         'наличии': 12189,\n",
       "         'препарат': 2082,\n",
       "         'профертил': 12,\n",
       "         '180': 2222,\n",
       "         'капсул': 1162,\n",
       "         'курс': 3877,\n",
       "         'месяца': 6360,\n",
       "         'привезен': 587,\n",
       "         'германии': 1977,\n",
       "         'ниже': 2582,\n",
       "         'аптеках': 157,\n",
       "         '10000': 1882,\n",
       "         'упаковку': 1165,\n",
       "         ...})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select only the tokens that had at least 10 occurences in the corpora.\n",
    "#Use token_counts.\n",
    "\n",
    "min_count = 10\n",
    "tokens = [key for key, value in token_counts.items() if value >= min_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87890"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['квартира',\n",
       " 'улучшенной',\n",
       " 'планировки',\n",
       " 'лоджия',\n",
       " '6',\n",
       " 'м',\n",
       " 'застеклена',\n",
       " 'большая',\n",
       " 'кухня',\n",
       " 'комнаты',\n",
       " 'изолированные',\n",
       " 'на',\n",
       " 'кухне',\n",
       " 'в',\n",
       " 'зале',\n",
       " 'и',\n",
       " 'коридоре',\n",
       " 'сделан',\n",
       " 'хороший',\n",
       " 'ремонт',\n",
       " 'выровнены',\n",
       " 'стены',\n",
       " 'натяжные',\n",
       " 'потолки',\n",
       " 'пол',\n",
       " 'кафель',\n",
       " 'ламинат',\n",
       " 'остальных',\n",
       " 'комнатах',\n",
       " 'линолеум',\n",
       " 'во',\n",
       " 'всех',\n",
       " 'пластиковые',\n",
       " 'окна',\n",
       " 'электропроводка',\n",
       " 'заменена',\n",
       " 'полностью',\n",
       " 'ванной',\n",
       " 'новая',\n",
       " 'сантехника',\n",
       " 'остается',\n",
       " 'шкаф',\n",
       " 'купе',\n",
       " 'встроенная',\n",
       " 'p',\n",
       " '62',\n",
       " '777',\n",
       " '8',\n",
       " 'phone',\n",
       " 'выбираете',\n",
       " 'автомобиль',\n",
       " 'боитесь',\n",
       " 'купить',\n",
       " 'кота',\n",
       " 'мешке',\n",
       " 'звоните',\n",
       " 'помогаем',\n",
       " 'выбрать',\n",
       " 'авто',\n",
       " 'с',\n",
       " 'пробегом',\n",
       " 'том',\n",
       " 'числе',\n",
       " 'газели',\n",
       " 'проверяем',\n",
       " 'наличие',\n",
       " 'скрытых',\n",
       " 'кузовных',\n",
       " 'дефектов',\n",
       " 'агрегатов',\n",
       " 'юридическое',\n",
       " 'сопровождение',\n",
       " 'сделки',\n",
       " 'оформление',\n",
       " 'договоров',\n",
       " 'купли',\n",
       " 'продажи',\n",
       " 'страховки',\n",
       " 'помощь',\n",
       " 'оформлением',\n",
       " 'гибдд',\n",
       " 'проверка',\n",
       " 'автомобиля',\n",
       " 'органах',\n",
       " 'выезд',\n",
       " 'специалиста',\n",
       " 'место',\n",
       " 'всего',\n",
       " '500',\n",
       " 'рублей',\n",
       " 'работаем',\n",
       " 'без',\n",
       " 'выходных',\n",
       " 'а',\n",
       " 'также',\n",
       " 'споры',\n",
       " 'касающиеся',\n",
       " 'оформления',\n",
       " 'транспортных',\n",
       " 'средств',\n",
       " 'прав',\n",
       " 'наследия',\n",
       " 'ареста',\n",
       " 'залога',\n",
       " 'спорных',\n",
       " 'вопросов',\n",
       " 'со',\n",
       " 'страховой',\n",
       " 'возмещение',\n",
       " 'убытков',\n",
       " 'консультации',\n",
       " 'представительство',\n",
       " 'суде',\n",
       " 'иных',\n",
       " 'инстанциях',\n",
       " 'опыт',\n",
       " 'работы',\n",
       " 'рынке',\n",
       " '16',\n",
       " 'лет',\n",
       " 'демисезонная',\n",
       " 'плюс',\n",
       " 'к',\n",
       " 'ней',\n",
       " 'отдам',\n",
       " 'штаны',\n",
       " 'комплект',\n",
       " 'новый',\n",
       " 'кальян',\n",
       " 'ни',\n",
       " 'разу',\n",
       " 'не',\n",
       " 'использовался',\n",
       " 'состояние',\n",
       " 'идеальное',\n",
       " 'упаковке',\n",
       " 'g',\n",
       " 'артикул',\n",
       " 'ge',\n",
       " 'автомат',\n",
       " 'коробочке',\n",
       " 'прайс',\n",
       " 'лист',\n",
       " 'март',\n",
       " '2014',\n",
       " 'название',\n",
       " 'мрц',\n",
       " 'базовая',\n",
       " 'цена',\n",
       " 'бц',\n",
       " 'от',\n",
       " 'руб',\n",
       " 'пачка',\n",
       " '1',\n",
       " 'бонд',\n",
       " 'стрит',\n",
       " 'лайт',\n",
       " 'пачке',\n",
       " '44',\n",
       " 'опт',\n",
       " 'цен',\n",
       " '40',\n",
       " '2',\n",
       " 'винстон',\n",
       " '54',\n",
       " '47',\n",
       " '3',\n",
       " 'донской',\n",
       " 'табак',\n",
       " 'тёмный',\n",
       " '35',\n",
       " '31',\n",
       " '5',\n",
       " '4',\n",
       " 'лм',\n",
       " 'синий',\n",
       " '42',\n",
       " 'красный',\n",
       " 'мальборо',\n",
       " 'белый',\n",
       " '74',\n",
       " '60',\n",
       " '7',\n",
       " 'парламент',\n",
       " '86',\n",
       " '73',\n",
       " '9',\n",
       " 'прима',\n",
       " 'дона',\n",
       " '29',\n",
       " '23',\n",
       " '10',\n",
       " 'св',\n",
       " 'георгий',\n",
       " '37',\n",
       " '33',\n",
       " '11',\n",
       " '12',\n",
       " 'тройка',\n",
       " '32',\n",
       " '13',\n",
       " '55',\n",
       " 'продам',\n",
       " 'платья',\n",
       " 'одеты',\n",
       " 'один',\n",
       " 'раз',\n",
       " 'до',\n",
       " '1000',\n",
       " 'удоставерение',\n",
       " 'ветерана',\n",
       " 'боевых',\n",
       " 'действий',\n",
       " 'срочно',\n",
       " 'через',\n",
       " 'юриста',\n",
       " 'переоформлением',\n",
       " 'ваше',\n",
       " 'имя',\n",
       " 'пожизненная',\n",
       " 'пенсия',\n",
       " 'льготы',\n",
       " 'права',\n",
       " 'получить',\n",
       " 'земельный',\n",
       " 'участок',\n",
       " 'любое',\n",
       " 'время',\n",
       " 'продается',\n",
       " 'дом',\n",
       " 'крыша',\n",
       " 'профиль',\n",
       " 'мпо',\n",
       " 'дверь',\n",
       " 'металлическая',\n",
       " 'документы',\n",
       " 'район',\n",
       " 'развитой',\n",
       " 'инфраструктурой',\n",
       " 'магазины',\n",
       " 'остановка',\n",
       " 'школа',\n",
       " 'садик',\n",
       " 'тел',\n",
       " 'фото',\n",
       " 'реальный',\n",
       " 'объект',\n",
       " 'акустика',\n",
       " 'известной',\n",
       " 'прошлом',\n",
       " 'компании',\n",
       " 'celestion',\n",
       " 'направленным',\n",
       " 'под',\n",
       " 'углом',\n",
       " 'который',\n",
       " 'находится',\n",
       " 'задней',\n",
       " 'стенке',\n",
       " 'сборка',\n",
       " 'англия',\n",
       " 'отличном',\n",
       " 'техническом',\n",
       " 'косметическом',\n",
       " 'состоянии',\n",
       " 'крайне',\n",
       " 'редкая',\n",
       " 'эта',\n",
       " 'линейка',\n",
       " '90',\n",
       " 'х',\n",
       " 'западную',\n",
       " 'своим',\n",
       " 'звучанием',\n",
       " 'относительно',\n",
       " 'небольшой',\n",
       " 'ценой',\n",
       " 'сцена',\n",
       " 'чувствительность',\n",
       " 'что',\n",
       " 'б',\n",
       " 'их',\n",
       " 'подключить',\n",
       " 'усилителю',\n",
       " 'комната',\n",
       " 'балконом',\n",
       " 'балкон',\n",
       " 'застеклен',\n",
       " 'сан',\n",
       " 'узел',\n",
       " 'общий',\n",
       " 'чисто',\n",
       " 'аккуратно',\n",
       " 'предложение',\n",
       " 'долгосрочный',\n",
       " 'период',\n",
       " 'сдается',\n",
       " 'чистенькая',\n",
       " 'квартире',\n",
       " 'есть',\n",
       " 'все',\n",
       " 'необходимое',\n",
       " 'для',\n",
       " 'проживания',\n",
       " 'холодильник',\n",
       " 'телевизор',\n",
       " 'стиральная',\n",
       " 'машина',\n",
       " 'нормальное',\n",
       " 'проведен',\n",
       " 'интернет',\n",
       " 'кабельное',\n",
       " 'телевидение',\n",
       " 'вид',\n",
       " 'из',\n",
       " 'спокойные',\n",
       " 'соседи',\n",
       " 'хозяева',\n",
       " 'город',\n",
       " 'приезжают',\n",
       " 'только',\n",
       " 'за',\n",
       " 'оплатой',\n",
       " 'возьмут',\n",
       " 'приличных',\n",
       " 'людей',\n",
       " 'просмотр',\n",
       " 'по',\n",
       " 'согласованию',\n",
       " 'агент',\n",
       " 'агентства',\n",
       " 'просьба',\n",
       " 'звонить',\n",
       " 'более',\n",
       " 'подробную',\n",
       " 'информацию',\n",
       " 'об',\n",
       " 'объекте',\n",
       " 'можно',\n",
       " 'узнать',\n",
       " 'нашем',\n",
       " 'сайте',\n",
       " 'ссылке',\n",
       " 'url',\n",
       " 'выбирая',\n",
       " 'abrecafe',\n",
       " 'вы',\n",
       " 'выполняете',\n",
       " 'четыре',\n",
       " 'задачи',\n",
       " 'одновременно',\n",
       " 'лишний',\n",
       " 'вес',\n",
       " 'деятельность',\n",
       " 'тела',\n",
       " 'активность',\n",
       " 'клеток',\n",
       " 'головного',\n",
       " 'мозга',\n",
       " 'наслаждаетесь',\n",
       " 'природным',\n",
       " 'вкусом',\n",
       " 'редкого',\n",
       " 'сорта',\n",
       " 'веса',\n",
       " 'абрекафе',\n",
       " 'этот',\n",
       " 'продукт',\n",
       " 'уже',\n",
       " 'известен',\n",
       " 'нашим',\n",
       " 'постоянным',\n",
       " 'покупателям',\n",
       " 'обладает',\n",
       " 'удивительными',\n",
       " 'свойствами',\n",
       " 'натурального',\n",
       " 'зеленого',\n",
       " 'кофе',\n",
       " 'похудения',\n",
       " 'как',\n",
       " 'же',\n",
       " 'способствует',\n",
       " 'похудению',\n",
       " 'причиной',\n",
       " 'излишнего',\n",
       " 'зачастую',\n",
       " 'является',\n",
       " 'правильное',\n",
       " 'питание',\n",
       " 'или',\n",
       " 'переедание',\n",
       " 'многие',\n",
       " 'люди',\n",
       " 'это',\n",
       " 'понимают',\n",
       " 'но',\n",
       " 'могут',\n",
       " 'справиться',\n",
       " 'этими',\n",
       " 'проблемами',\n",
       " 'самостоятельно',\n",
       " 'натуральный',\n",
       " 'зеленый',\n",
       " 'хлорогеновая',\n",
       " 'кислота',\n",
       " 'одним',\n",
       " 'натуральных',\n",
       " 'природных',\n",
       " 'компонентов',\n",
       " 'заставляющих',\n",
       " 'организм',\n",
       " 'человека',\n",
       " 'сжигать',\n",
       " 'жиры',\n",
       " 'вместо',\n",
       " 'углеводов',\n",
       " 'при',\n",
       " 'вырабатывании',\n",
       " 'энергии',\n",
       " 'согласно',\n",
       " 'результатам',\n",
       " 'проведенного',\n",
       " 'исследования',\n",
       " 'содержит',\n",
       " 'хлорогеновой',\n",
       " 'кислоты',\n",
       " 'счет',\n",
       " 'этого',\n",
       " 'отбивает',\n",
       " 'чрезмерный',\n",
       " 'аппетит',\n",
       " 'человек',\n",
       " 'быстрее',\n",
       " 'насыщается',\n",
       " 'почему',\n",
       " 'именно',\n",
       " 'если',\n",
       " 'цель',\n",
       " 'похудеть',\n",
       " 'вреда',\n",
       " 'здоровья',\n",
       " 'тогда',\n",
       " 'нужно',\n",
       " 'внимательно',\n",
       " 'относиться',\n",
       " 'тому',\n",
       " 'употребляете',\n",
       " 'перед',\n",
       " 'нами',\n",
       " 'задача',\n",
       " 'зеленых',\n",
       " 'зерен',\n",
       " 'содержащих',\n",
       " 'хлорогеновую',\n",
       " 'кислоту',\n",
       " 'вывести',\n",
       " 'вредные',\n",
       " 'вещества',\n",
       " 'этом',\n",
       " 'сохранить',\n",
       " 'максимальное',\n",
       " 'содержание',\n",
       " 'каждом',\n",
       " 'зерне',\n",
       " 'того',\n",
       " 'чтобы',\n",
       " 'зерна',\n",
       " 'исключительно',\n",
       " 'положительно',\n",
       " 'необходимо',\n",
       " 'термической',\n",
       " 'обработке',\n",
       " 'после',\n",
       " 'такой',\n",
       " 'обработки',\n",
       " 'выводятся',\n",
       " 'было',\n",
       " 'сказано',\n",
       " 'выше',\n",
       " 'содержится',\n",
       " 'около',\n",
       " 'так',\n",
       " 'вот',\n",
       " 'вам',\n",
       " 'готов',\n",
       " 'употреблению',\n",
       " 'эффективен',\n",
       " 'безопасен',\n",
       " 'подтверждено',\n",
       " 'независимыми',\n",
       " 'испытаниями',\n",
       " 'полезные',\n",
       " 'свойства',\n",
       " 'термически',\n",
       " 'обработанного',\n",
       " 'помимо',\n",
       " 'уменьшает',\n",
       " 'риск',\n",
       " 'переедания',\n",
       " 'он',\n",
       " 'рядом',\n",
       " 'других',\n",
       " 'интересных',\n",
       " 'полезных',\n",
       " 'свойств',\n",
       " 'стимулирование',\n",
       " 'двигательной',\n",
       " 'активности',\n",
       " 'повышает',\n",
       " 'двигательную',\n",
       " 'высокого',\n",
       " 'содержания',\n",
       " 'природного',\n",
       " 'кофеина',\n",
       " 'являющегося',\n",
       " 'натуральной',\n",
       " 'составляющей',\n",
       " 'продукта',\n",
       " 'начинает',\n",
       " 'чувствовать',\n",
       " 'себя',\n",
       " 'бодро',\n",
       " 'выполнять',\n",
       " 'больше',\n",
       " 'дел',\n",
       " 'становится',\n",
       " 'способен',\n",
       " 'произвести',\n",
       " 'физических',\n",
       " 'нагрузок',\n",
       " 'человеку',\n",
       " 'гораздо',\n",
       " 'проще',\n",
       " 'начать',\n",
       " 'заниматься',\n",
       " 'спортом',\n",
       " 'этим',\n",
       " 'занимался',\n",
       " 'повышение',\n",
       " 'умственных',\n",
       " 'способностей',\n",
       " 'деятельности',\n",
       " 'происходит',\n",
       " 'благодаря',\n",
       " 'танину',\n",
       " 'ещё',\n",
       " 'одному',\n",
       " 'натуральному',\n",
       " 'компоненту',\n",
       " 'стоит',\n",
       " 'обратить',\n",
       " 'противопоказания',\n",
       " 'прежде',\n",
       " 'чем',\n",
       " 'пить',\n",
       " 'рекомендуется',\n",
       " 'гипертонии',\n",
       " 'нарушении',\n",
       " 'сердечной',\n",
       " 'беременность',\n",
       " 'индивидуальной',\n",
       " 'непереносимости',\n",
       " 'женщинам',\n",
       " 'кормящим',\n",
       " 'грудью',\n",
       " 'вещи',\n",
       " 'фирменные',\n",
       " 'хорошем',\n",
       " 'продаю',\n",
       " 'пакетом',\n",
       " 'стоимость',\n",
       " 'вещичек',\n",
       " '500р',\n",
       " 'восстановление',\n",
       " 'энергетики',\n",
       " 'преображение',\n",
       " 'будущего',\n",
       " 'снятие',\n",
       " 'негатива',\n",
       " 'смотрим',\n",
       " 'спа',\n",
       " 'программы',\n",
       " 'выходя',\n",
       " 'дома',\n",
       " 'уникальное',\n",
       " 'супер',\n",
       " 'программам',\n",
       " 'массажу',\n",
       " 'возрастов',\n",
       " 'скраб',\n",
       " 'гидромассаж',\n",
       " 'антицеллюлитный',\n",
       " 'массаж',\n",
       " 'оздоровительный',\n",
       " 'гуаша',\n",
       " 'антицеллюлитное',\n",
       " 'шоколадное',\n",
       " 'обертывание',\n",
       " 'завершение',\n",
       " 'потрясающий',\n",
       " 'крем',\n",
       " 'телу',\n",
       " 'вытяжкой',\n",
       " 'икры',\n",
       " 'лососевых',\n",
       " 'процедуры',\n",
       " 'провожу',\n",
       " 'лично',\n",
       " 'профессиональный',\n",
       " 'стаж',\n",
       " '1992',\n",
       " 'года',\n",
       " 'эти',\n",
       " 'цифры',\n",
       " '22',\n",
       " 'тысячи',\n",
       " 'благодарных',\n",
       " 'клиентов',\n",
       " 'такого',\n",
       " 'еще',\n",
       " 'пробовали',\n",
       " 'упустите',\n",
       " 'шанс',\n",
       " 'шикарную',\n",
       " 'процедуру',\n",
       " 'своего',\n",
       " 'kpeдит',\n",
       " 'чеpез',\n",
       " 'интеpнeт',\n",
       " 'справок',\n",
       " 'поручителей',\n",
       " 'владивосток',\n",
       " 'пoлyчитe',\n",
       " 'кpедит',\n",
       " 'зa',\n",
       " 'нecкoлько',\n",
       " 'минут',\n",
       " 'одобряются',\n",
       " 'бeз',\n",
       " '000',\n",
       " 'pyб',\n",
       " 'выдачa',\n",
       " 'кpедитa',\n",
       " 'день',\n",
       " 'oдобрeние',\n",
       " 'посeщения',\n",
       " 'офиса',\n",
       " 'бaнка',\n",
       " 'пpоверки',\n",
       " 'кpeдитной',\n",
       " 'истoрии',\n",
       " 'oзнакомиться',\n",
       " 'c',\n",
       " 'yслoвиями',\n",
       " 'оcтавить',\n",
       " 'заявку',\n",
       " 'мoжнo',\n",
       " 'caйте',\n",
       " 'kод',\n",
       " 'oбъявления',\n",
       " 'виды',\n",
       " 'компьютерной',\n",
       " 'помощи',\n",
       " 'ук',\n",
       " 'рф',\n",
       " 'всем',\n",
       " 'вопросам',\n",
       " 'почту',\n",
       " 'мне',\n",
       " '19лет',\n",
       " 'рост',\n",
       " '168',\n",
       " '45',\n",
       " 'блондинка',\n",
       " 'ищу',\n",
       " 'парня',\n",
       " '20',\n",
       " '26',\n",
       " 'серьезные',\n",
       " 'отношения',\n",
       " 'судимые',\n",
       " 'беспокоить',\n",
       " 'т',\n",
       " 'комнатную',\n",
       " 'квартиру',\n",
       " 'солнечном',\n",
       " 'этаж',\n",
       " 'этажном',\n",
       " 'панельном',\n",
       " 'доме',\n",
       " '18',\n",
       " '50',\n",
       " 'спальня',\n",
       " '70',\n",
       " 'большой',\n",
       " 'комнате',\n",
       " '0',\n",
       " 'кв',\n",
       " 'деревянные',\n",
       " 'туалет',\n",
       " 'кафеля',\n",
       " 'снимаю',\n",
       " 'порчу',\n",
       " 'опухоль',\n",
       " 'сглаз',\n",
       " 'восстанавливаю',\n",
       " 'ауру',\n",
       " 'предсказание',\n",
       " 'точное',\n",
       " 'прошлого',\n",
       " 'недорого',\n",
       " 'валентина',\n",
       " 'новостройка',\n",
       " '80м',\n",
       " 'евроремонт',\n",
       " 'частично',\n",
       " 'советских',\n",
       " 'времён',\n",
       " 'превосходный',\n",
       " 'подарок',\n",
       " 'новому',\n",
       " 'году',\n",
       " 'у',\n",
       " 'вас',\n",
       " 'появилась',\n",
       " 'возможность',\n",
       " 'преобрести',\n",
       " 'арбалет',\n",
       " 'цене',\n",
       " 'ведь',\n",
       " 'оно',\n",
       " 'математика',\n",
       " 'информатика',\n",
       " 'программирование',\n",
       " 'delphi',\n",
       " 'pascal',\n",
       " 'упаковка',\n",
       " '250',\n",
       " 'гр',\n",
       " 'заказывала',\n",
       " 'пока',\n",
       " 'шел',\n",
       " 'заказ',\n",
       " 'узнала',\n",
       " 'беременна',\n",
       " 'поэтому',\n",
       " 'покупала',\n",
       " 'сдам',\n",
       " 'новогодний',\n",
       " 'площадь',\n",
       " 'трц',\n",
       " 'июнь',\n",
       " 'новой',\n",
       " 'р',\n",
       " 'н',\n",
       " 'пчелка',\n",
       " 'кадастровый',\n",
       " 'номер',\n",
       " '36',\n",
       " '788',\n",
       " 'смотреть',\n",
       " 'публичной',\n",
       " 'кадастровой',\n",
       " 'карте',\n",
       " 'интернете',\n",
       " 'номеру',\n",
       " 'адрес',\n",
       " 'усмань',\n",
       " 'ул',\n",
       " 'торг',\n",
       " 'контрольные',\n",
       " 'выполнением',\n",
       " 'домашнего',\n",
       " 'задания',\n",
       " 'перевод',\n",
       " 'требуется',\n",
       " 'повар',\n",
       " 'универсал',\n",
       " 'любящий',\n",
       " 'свою',\n",
       " 'работу',\n",
       " 'хорошее',\n",
       " 'отношение',\n",
       " 'работе',\n",
       " 'нас',\n",
       " 'достойная',\n",
       " 'заработная',\n",
       " 'плата',\n",
       " 'перспективой',\n",
       " 'ее',\n",
       " 'роста',\n",
       " 'повышения',\n",
       " 'должности',\n",
       " 'систематизировать',\n",
       " 'кухню',\n",
       " 'сделать',\n",
       " 'вкусно',\n",
       " 'сказать',\n",
       " 'работа',\n",
       " 'нуля',\n",
       " 'определённые',\n",
       " 'наработки',\n",
       " 'абсолютно',\n",
       " 'египта',\n",
       " '64',\n",
       " 'cм',\n",
       " 'крeдит',\n",
       " 'чеpeз',\n",
       " 'cправок',\n",
       " 'поручителeй',\n",
       " 'миасс',\n",
       " 'офоpмите',\n",
       " 'нeскoлько',\n",
       " 'дo',\n",
       " 'pуб',\n",
       " 'bыдачa',\n",
       " 'oдобpение',\n",
       " 'пoсeщения',\n",
       " 'oфиса',\n",
       " 'банкa',\n",
       " 'пpовеpки',\n",
       " 'кpeдитнoй',\n",
       " 'истopии',\n",
       " 'oзнакомитьcя',\n",
       " 'oставить',\n",
       " 'зaявкy',\n",
       " 'можнo',\n",
       " 'cайтe',\n",
       " 'объявления',\n",
       " '80',\n",
       " 'п',\n",
       " 'соток',\n",
       " '450',\n",
       " '000р',\n",
       " 'ижс',\n",
       " 'собственности',\n",
       " 'продолжение',\n",
       " 'проспекта',\n",
       " 'мира',\n",
       " 'электричество',\n",
       " 'проводят',\n",
       " 'остальные',\n",
       " 'улицы',\n",
       " 'коммуникации',\n",
       " 'федеральной',\n",
       " 'программе',\n",
       " 'газ',\n",
       " '2015г',\n",
       " '28',\n",
       " 'малая',\n",
       " '430',\n",
       " '680',\n",
       " '750',\n",
       " '000руб',\n",
       " '300000р',\n",
       " 'земля',\n",
       " '2013г',\n",
       " 'км',\n",
       " 'города',\n",
       " 'ясной',\n",
       " 'поляны',\n",
       " 'дачное',\n",
       " 'назначение',\n",
       " 'лес',\n",
       " 'кама',\n",
       " '140',\n",
       " 'районе',\n",
       " 'новое',\n",
       " 'здание',\n",
       " 'участке',\n",
       " '06',\n",
       " 'га',\n",
       " 'застройки',\n",
       " '375',\n",
       " 'договор',\n",
       " 'долгосрочной',\n",
       " 'аренды',\n",
       " 'участка',\n",
       " '2008',\n",
       " 'г',\n",
       " 'высокие',\n",
       " 'самые',\n",
       " 'современный',\n",
       " 'инженерные',\n",
       " 'системы',\n",
       " 'оптико',\n",
       " 'волоконная',\n",
       " 'связь',\n",
       " 'подземная',\n",
       " 'двухуровневая',\n",
       " 'парковка',\n",
       " '24',\n",
       " 'машины',\n",
       " 'свободная',\n",
       " 'планировка',\n",
       " 'core',\n",
       " 'электроснабжение',\n",
       " '215',\n",
       " 'ква',\n",
       " 'переулок',\n",
       " 'базе',\n",
       " 'мужчин',\n",
       " 'специальная',\n",
       " 'техника',\n",
       " 'глубокого',\n",
       " 'расслабления',\n",
       " 'помогает',\n",
       " 'отдохнуть',\n",
       " 'восстановиться',\n",
       " 'воздействует',\n",
       " 'энергетику',\n",
       " 'душевное',\n",
       " 'равновесие',\n",
       " 'индивидуальный',\n",
       " 'подход',\n",
       " 'каждому',\n",
       " 'сделаю',\n",
       " 'английскому',\n",
       " 'немецкому',\n",
       " 'языку',\n",
       " 'мебели',\n",
       " 'длительный',\n",
       " 'срок',\n",
       " 'классический',\n",
       " 'детский',\n",
       " 'жилая',\n",
       " 'пластик',\n",
       " 'тыс',\n",
       " 'блок',\n",
       " 'розжига',\n",
       " 'hid',\n",
       " 'пластиковый',\n",
       " 'тонкий',\n",
       " '16v',\n",
       " 'ксенона',\n",
       " 'гарантия',\n",
       " 'наличии',\n",
       " 'препарат',\n",
       " 'профертил',\n",
       " '180',\n",
       " 'капсул',\n",
       " 'курс',\n",
       " 'месяца',\n",
       " 'привезен',\n",
       " 'германии',\n",
       " 'ниже',\n",
       " 'аптеках',\n",
       " '10000',\n",
       " 'упаковку',\n",
       " 'продукцию',\n",
       " 'тяньши',\n",
       " 'рамки',\n",
       " 'перевертыши',\n",
       " '6000р',\n",
       " 'очень',\n",
       " 'удобные',\n",
       " 'мягкие',\n",
       " '38',\n",
       " '39',\n",
       " 'стелька',\n",
       " '25',\n",
       " 'подойдут',\n",
       " 'узкую',\n",
       " 'яичек',\n",
       " 'киндер',\n",
       " 'ребенка',\n",
       " '150р',\n",
       " 'о',\n",
       " 'применении',\n",
       " 'медвежьего',\n",
       " 'жира',\n",
       " 'народной',\n",
       " 'медицине',\n",
       " 'самым',\n",
       " 'ценным',\n",
       " 'считается',\n",
       " 'жир',\n",
       " 'зверей',\n",
       " 'медведя',\n",
       " 'барсука',\n",
       " 'возможно',\n",
       " 'его',\n",
       " 'целебные',\n",
       " 'биологически',\n",
       " 'активных',\n",
       " 'веществ',\n",
       " 'необходимых',\n",
       " 'сохранения',\n",
       " 'нормальной',\n",
       " 'жизнедеятельности',\n",
       " 'течение',\n",
       " 'нескольких',\n",
       " 'месяцев',\n",
       " 'пищи',\n",
       " 'воды',\n",
       " 'медвежий',\n",
       " 'издавна',\n",
       " 'эффективным',\n",
       " 'средством',\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t:i+1 for i,t in enumerate(tokens)}\n",
    "null_token = \"NULL\"\n",
    "token_to_id[null_token] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tokens: 87891\n",
      "Alarm! Too many tokens. You might have messed up when pruning rare ones -- unless you know what you're doin' ofc\n"
     ]
    }
   ],
   "source": [
    "print(\"# Tokens:\",len(token_to_id))\n",
    "if len(token_to_id) < 30000:\n",
    "    print(\"Alarm! It seems like there are too few tokens. Make sure you updated NLTK and applied correct thresholds -- unless you now what you're doing, ofc\")\n",
    "if len(token_to_id) < 1000000:\n",
    "    print(\"Alarm! Too many tokens. You might have messed up when pruning rare ones -- unless you know what you're doin' ofc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace words with IDs\n",
    "Set a maximum length for titles and descriptions.\n",
    " * If string is longer that that limit - crop it, if less - pad with zeros.\n",
    " * Thus we obtain a matrix of size [n_samples]x[max_length]\n",
    " * Element at i,j - is an identifier of word j within sample i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(strings, token_to_id, max_len=150):\n",
    "    token_matrix = []\n",
    "    for s in strings:\n",
    "        if type(s) is not str:\n",
    "            token_matrix.append([0]*max_len)\n",
    "            continue\n",
    "        s = s.lower()\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        token_ids = list(map(lambda token: token_to_id.get(token,0), tokens))[:max_len]\n",
    "        token_ids += [0]*(max_len - len(token_ids))\n",
    "        token_matrix.append(token_ids)\n",
    "\n",
    "    return np.array(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_tokens = vectorize(df.description.values,token_to_id,max_len = 150)\n",
    "title_tokens = vectorize(df.title.values,token_to_id,max_len = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (550000, 15)\n",
      "2-к квартира, 47 м², 2/4 эт. -> [ 163  123    1  166 1193  163  174 4165    0    0] ...\n",
      "Помогаем выбрать авто с пробегом -> [57 58 59 60 61  0  0  0  0  0] ...\n",
      "Куртка плюс штаны -> [1814  122  126    0    0    0    0    0    0    0] ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы:\",title_tokens.shape)\n",
    "for title, tokens in zip(df.title.values[:3],title_tokens[:3]):\n",
    "    print(title,'->', tokens[:10],'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ As you can see, our preprocessing is somewhat crude. Let us see if that is enough for our network __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-sequences\n",
    "\n",
    "\n",
    "Some data features are not text samples. E.g. price, # urls, category, etc\n",
    "\n",
    "They require a separate preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All numeric features\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot-encoded category and subcategory\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categories = []\n",
    "info = {}\n",
    "data_cat_subcat = df[[\"category\",\"subcategory\"]].values\n",
    "\n",
    "categories = [{\"category\": item[0], \"subcategory\": item[1]} for item in data_cat_subcat]\n",
    "\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(\n",
    "    df_numerical_features,cat_one_hot,on = np.arange(len(cat_one_hot))\n",
    ")\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Target variable - whether or not sample contains prohibited material\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#Preprocessed titles\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#Preprocessed tokens\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "\n",
    "#Non-sequences\n",
    "df_non_text = df_non_text.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440000.0\n"
     ]
    }
   ],
   "source": [
    "print(len(target)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into training and test set.\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#df_train , df_test, df_non_text_train, df_non_text_test = train_test_split(df, df_non_text, test_size=0.3, random_state=42)\n",
    "\n",
    "#Difficulty selector:\n",
    "#Easy: split randomly\n",
    "#Medium: select test set items that have item_ids strictly above that of training set\n",
    "#Hard: do whatever you want, but score yourself using kaggle private leaderboard\n",
    "\n",
    "# title_tr = df_train[\"title\"]\n",
    "# title_ts = df_test[\"title\"]\n",
    "# desc_tr = df_train[\"description\"]\n",
    "# desc_ts = df_test[\"description\"]\n",
    "# nontext_tr = df_non_text_train\n",
    "# nontext_ts = df_non_text_test\n",
    "# target_tr = df_train[\"is_blocked\"]\n",
    "# target_ts = df_test[\"is_blocked\"]\n",
    "\n",
    "title_tr = title_tokens[:440000]\n",
    "title_ts = title_tokens[440000:]\n",
    "desc_tr = desc_tokens[:440000]\n",
    "desc_ts = desc_tokens[440000:]\n",
    "nontext_tr = df_non_text[:440000]\n",
    "nontext_ts = df_non_text[440000:]\n",
    "target_tr = target[:440000]\n",
    "target_ts = target[440000:]\n",
    "\n",
    "\n",
    "\n",
    "data_tuple = (title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(title_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(target)*0.8 # 440000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440000\n"
     ]
    }
   ],
   "source": [
    "print(len(title_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data [optional]\n",
    "\n",
    "* The next tab can be used to stash all the essential data matrices and get rid of the rest of the data.\n",
    " * Highly recommended if you have less than 1.5GB RAM left\n",
    "* To do that, you need to first run it with save_prepared_data=True, then restart the notebook and only run this tab with read_prepared_data=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading saved data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "save_prepared_data = False #save\n",
    "read_prepared_data = True #load\n",
    "\n",
    "#but not both at once\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "if save_prepared_data:\n",
    "    print(\"Saving preprocessed data (may take up to 3 minutes)\")\n",
    "\n",
    "    import pickle\n",
    "    with open(\"preprocessed_data.pcl\", 'wb') as fout:\n",
    "        pickle.dump(data_tuple, fout)\n",
    "    with open(\"token_to_id.pcl\", 'wb') as fout:\n",
    "        pickle.dump(token_to_id, fout)\n",
    "\n",
    "    print(\"готово\")\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print(\"Reading saved data...\")\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data.pcl\", 'rb') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_train, title_test, desc_train, desc_test, nontext_train, nontext_test, target_train, target_test = data_tuple\n",
    "    with open(\"token_to_id.pcl\", 'rb') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "        \n",
    "    #Re-importing libraries to allow staring noteboook from here\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "   \n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнено в Keras, тк с lasagne возникли проблемы на 2 и 3 питоне..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title_train = np.asarray(title_tr)\n",
    "title_test = np.asarray(title_ts)\n",
    "desc_train = np.asarray(desc_tr)\n",
    "desc_test = np.asarray(desc_ts)\n",
    "target_train = np.asarray(target_tr)\n",
    "target_test = np.asarray(target_ts)\n",
    "nontext_train = nontext_tr\n",
    "nontext_test = nontext_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440000\n",
      "110000\n",
      "440000\n",
      "110000\n",
      "440000\n",
      "110000\n",
      "440000\n",
      "110000\n"
     ]
    }
   ],
   "source": [
    "print(len(title_train))\n",
    "print(len(title_test))\n",
    "print(len(desc_train))\n",
    "print(len(desc_test))\n",
    "print(len(nontext_train))\n",
    "print(len(nontext_test))\n",
    "print(len(target_train))\n",
    "print(len(target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Dense, RepeatVector, Permute, Flatten, Activation, Lambda, merge\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.optimizers import Nadam, RMSprop, Adagrad, Adam, Adadelta\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout, Reshape\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.merge import multiply, add\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.core import Layer  \n",
    "from keras import initializers, regularizers, constraints, activations, initializers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import metrics\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 150) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_desc = Input(shape=(150,), dtype='float32')\n",
    "inputs_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reccurent_model():\n",
    "    \n",
    "    inputs_titile = Input(shape=(15,), dtype='float32')\n",
    "    inputs_desc = Input(shape=(150,), dtype='float32')\n",
    "    inputs_nontext = Input(shape=(67,), dtype='float32')\n",
    "    \n",
    "    encoded_titile = Embedding(87953, 60, input_length=15,\n",
    "                          trainable=True, mask_zero=True,)(inputs_titile)\n",
    "    \n",
    "    encoded_desc = Embedding(87953, 60, input_length=150,\n",
    "                             trainable=True, mask_zero=True,)(inputs_desc)\n",
    "    \n",
    "    activations_title = Bidirectional(LSTM(60, recurrent_dropout=0.2, dropout=0.2, return_sequences=False))(encoded_titile)\n",
    "\n",
    "    activations_desc = Bidirectional(LSTM(60, recurrent_dropout=0.2, dropout=0.2, return_sequences=False))(encoded_desc)\n",
    "\n",
    "    dense1 = Dense(32)(inputs_nontext)\n",
    "    bn1 = BatchNormalization()(dense1)\n",
    "    relu1 = PReLU()(bn1)\n",
    "\n",
    "    dense2 = Dense(32)(relu1)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    res2 = add([relu1, bn2])\n",
    "    relu2 = PReLU()(res2)     \n",
    "    \n",
    "    feats = concatenate([relu2, relu1])\n",
    "    \n",
    "    merged = concatenate([activations_title, activations_desc, feats])\n",
    "    \n",
    "    \n",
    "    \n",
    "    merged = Dense(100)(merged)\n",
    "\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Activation(\"relu\")(merged)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid', name='outputs')(merged)\n",
    "    my_loss = {'outputs': \"binary_crossentropy\",}\n",
    "\n",
    "    inputs_all = [\n",
    "                inputs_titile,\n",
    "                inputs_desc,\n",
    "                inputs_nontext\n",
    "            ]\n",
    "\n",
    "    outputs_all = [\n",
    "                outputs\n",
    "            ]\n",
    "\n",
    "    model = Model(inputs=inputs_all, outputs=outputs_all)\n",
    "    nadam = Nadam(lr=1e-2)\n",
    "\n",
    "    model.compile(\n",
    "                optimizer=nadam,\n",
    "                loss=my_loss,\n",
    "                loss_weights={'outputs': 1.},\n",
    "                metrics=[metrics.binary_crossentropy, metrics.binary_accuracy]\n",
    "              )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def APatK(y_true, y_predicted, K=32500):\n",
    "    \"\"\"Calculates AP@k given true Y and predictions (probabilities).\n",
    "    Sorts answers by y_predicted to obtain ranking\"\"\"\n",
    "\n",
    "    sort_by_ypred = np.argsort(-y_predicted)\n",
    "    \n",
    "    y_true = y_true[sort_by_ypred]\n",
    "    y_predicted = y_predicted[sort_by_ypred]\n",
    "    \n",
    "    countRelevants = 0\n",
    "    listOfPrecisions = []\n",
    "    \n",
    "    for i in range(min(K, y_true.shape[0])):\n",
    "        currentk = i + 1.0\n",
    "        if y_true[i] != 0:\n",
    "            countRelevants += 1\n",
    "\n",
    "        precisionAtK = countRelevants / currentk \n",
    "        listOfPrecisions.append(precisionAtK)\n",
    "    return np.sum(listOfPrecisions) / min(K, y_true.shape[0]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer = StandardScaler()\n",
    "nontext_matrix_train = transformer.fit_transform(nontext_train.as_matrix())\n",
    "nontext_matrix_test = transformer.transform(nontext_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 184s - loss: 0.2473 - binary_crossentropy: 0.2473 - binary_accuracy: 0.9000 - val_loss: 0.2238 - val_binary_crossentropy: 0.2238 - val_binary_accuracy: 0.9158\n",
      "epoch:  0\n",
      "auc:  0.978542172712\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 183s - loss: 0.1728 - binary_crossentropy: 0.1728 - binary_accuracy: 0.9338 - val_loss: 0.1496 - val_binary_crossentropy: 0.1496 - val_binary_accuracy: 0.9444\n",
      "epoch:  1\n",
      "auc:  0.987721867273\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 209s - loss: 0.1494 - binary_crossentropy: 0.1494 - binary_accuracy: 0.9441 - val_loss: 0.1487 - val_binary_crossentropy: 0.1487 - val_binary_accuracy: 0.9429\n",
      "epoch:  2\n",
      "auc:  0.986902278854\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 180s - loss: 0.1287 - binary_crossentropy: 0.1287 - binary_accuracy: 0.9530 - val_loss: 0.1260 - val_binary_crossentropy: 0.1260 - val_binary_accuracy: 0.9540\n",
      "epoch:  3\n",
      "auc:  0.990613106345\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 176s - loss: 0.1179 - binary_crossentropy: 0.1179 - binary_accuracy: 0.9581 - val_loss: 0.1394 - val_binary_crossentropy: 0.1394 - val_binary_accuracy: 0.9546\n",
      "epoch:  4\n",
      "auc:  0.990456430921\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 193s - loss: 0.1267 - binary_crossentropy: 0.1267 - binary_accuracy: 0.9561 - val_loss: 0.1176 - val_binary_crossentropy: 0.1176 - val_binary_accuracy: 0.9568\n",
      "epoch:  5\n",
      "auc:  0.991753472031\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 189s - loss: 0.1148 - binary_crossentropy: 0.1148 - binary_accuracy: 0.9596 - val_loss: 0.1411 - val_binary_crossentropy: 0.1411 - val_binary_accuracy: 0.9469\n",
      "epoch:  6\n",
      "auc:  0.99163016545\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 170s - loss: 0.1104 - binary_crossentropy: 0.1104 - binary_accuracy: 0.9622 - val_loss: 0.1772 - val_binary_crossentropy: 0.1772 - val_binary_accuracy: 0.9339\n",
      "epoch:  7\n",
      "auc:  0.990391174516\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 170s - loss: 0.1102 - binary_crossentropy: 0.1102 - binary_accuracy: 0.9618 - val_loss: 0.1488 - val_binary_crossentropy: 0.1488 - val_binary_accuracy: 0.9412\n",
      "epoch:  8\n",
      "auc:  0.991711075385\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 169s - loss: 0.1005 - binary_crossentropy: 0.1005 - binary_accuracy: 0.9664 - val_loss: 0.1074 - val_binary_crossentropy: 0.1074 - val_binary_accuracy: 0.9629\n",
      "epoch:  9\n",
      "auc:  0.993097093404\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 169s - loss: 0.1080 - binary_crossentropy: 0.1080 - binary_accuracy: 0.9637 - val_loss: 0.1286 - val_binary_crossentropy: 0.1286 - val_binary_accuracy: 0.9535\n",
      "epoch:  10\n",
      "auc:  0.992697007585\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.0920 - binary_crossentropy: 0.0920 - binary_accuracy: 0.9698 - val_loss: 0.1092 - val_binary_crossentropy: 0.1092 - val_binary_accuracy: 0.9617\n",
      "epoch:  11\n",
      "auc:  0.992972605802\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 174s - loss: 0.1005 - binary_crossentropy: 0.1005 - binary_accuracy: 0.9650 - val_loss: 0.1367 - val_binary_crossentropy: 0.1367 - val_binary_accuracy: 0.9492\n",
      "epoch:  12\n",
      "auc:  0.992970624089\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 173s - loss: 0.1092 - binary_crossentropy: 0.1092 - binary_accuracy: 0.9613 - val_loss: 0.1018 - val_binary_crossentropy: 0.1018 - val_binary_accuracy: 0.9626\n",
      "epoch:  13\n",
      "auc:  0.993281092445\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.0946 - binary_crossentropy: 0.0946 - binary_accuracy: 0.9682 - val_loss: 0.1152 - val_binary_crossentropy: 0.1152 - val_binary_accuracy: 0.9602\n",
      "epoch:  14\n",
      "auc:  0.993059020495\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.1023 - binary_crossentropy: 0.1023 - binary_accuracy: 0.9628 - val_loss: 0.1162 - val_binary_crossentropy: 0.1162 - val_binary_accuracy: 0.9579\n",
      "epoch:  15\n",
      "auc:  0.993545440937\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 169s - loss: 0.1000 - binary_crossentropy: 0.1000 - binary_accuracy: 0.9667 - val_loss: 0.1049 - val_binary_crossentropy: 0.1049 - val_binary_accuracy: 0.9648\n",
      "epoch:  16\n",
      "auc:  0.993345668262\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.0940 - binary_crossentropy: 0.0940 - binary_accuracy: 0.9672 - val_loss: 0.1016 - val_binary_crossentropy: 0.1016 - val_binary_accuracy: 0.9642\n",
      "epoch:  17\n",
      "auc:  0.994047434841\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.0977 - binary_crossentropy: 0.0977 - binary_accuracy: 0.9648 - val_loss: 0.1010 - val_binary_crossentropy: 0.1010 - val_binary_accuracy: 0.9658\n",
      "epoch:  18\n",
      "auc:  0.993992367243\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 169s - loss: 0.0965 - binary_crossentropy: 0.0965 - binary_accuracy: 0.9677 - val_loss: 0.1151 - val_binary_crossentropy: 0.1151 - val_binary_accuracy: 0.9592\n",
      "epoch:  19\n",
      "auc:  0.992479739788\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.1000 - binary_crossentropy: 0.1000 - binary_accuracy: 0.9656 - val_loss: 0.1375 - val_binary_crossentropy: 0.1375 - val_binary_accuracy: 0.9520\n",
      "epoch:  20\n",
      "auc:  0.99352264123\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.1081 - binary_crossentropy: 0.1081 - binary_accuracy: 0.9664 - val_loss: 0.4573 - val_binary_crossentropy: 0.4573 - val_binary_accuracy: 0.8822\n",
      "epoch:  21\n",
      "auc:  0.977174150249\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 169s - loss: 0.0933 - binary_crossentropy: 0.0933 - binary_accuracy: 0.9704 - val_loss: 0.1772 - val_binary_crossentropy: 0.1772 - val_binary_accuracy: 0.9469\n",
      "epoch:  22\n",
      "auc:  0.991220571413\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.0932 - binary_crossentropy: 0.0932 - binary_accuracy: 0.9710 - val_loss: 0.1007 - val_binary_crossentropy: 0.1007 - val_binary_accuracy: 0.9672\n",
      "epoch:  23\n",
      "auc:  0.994393734168\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.0966 - binary_crossentropy: 0.0966 - binary_accuracy: 0.9694 - val_loss: 0.1032 - val_binary_crossentropy: 0.1032 - val_binary_accuracy: 0.9666\n",
      "epoch:  24\n",
      "auc:  0.994308300322\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.0968 - binary_crossentropy: 0.0968 - binary_accuracy: 0.9681 - val_loss: 0.1018 - val_binary_crossentropy: 0.1018 - val_binary_accuracy: 0.9673\n",
      "epoch:  25\n",
      "auc:  0.994147141023\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 167s - loss: 0.0984 - binary_crossentropy: 0.0984 - binary_accuracy: 0.9680 - val_loss: 0.3837 - val_binary_crossentropy: 0.3837 - val_binary_accuracy: 0.9069\n",
      "epoch:  26\n",
      "auc:  0.985667431501\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.1011 - binary_crossentropy: 0.1011 - binary_accuracy: 0.9698 - val_loss: 0.1885 - val_binary_crossentropy: 0.1885 - val_binary_accuracy: 0.9478\n",
      "epoch:  27\n",
      "auc:  0.989013263504\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.0992 - binary_crossentropy: 0.0992 - binary_accuracy: 0.9673 - val_loss: 0.1034 - val_binary_crossentropy: 0.1034 - val_binary_accuracy: 0.9672\n",
      "epoch:  28\n",
      "auc:  0.993491974723\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.0915 - binary_crossentropy: 0.0915 - binary_accuracy: 0.9720 - val_loss: 0.0990 - val_binary_crossentropy: 0.0990 - val_binary_accuracy: 0.9670\n",
      "epoch:  29\n",
      "auc:  0.993933876686\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.1037 - binary_crossentropy: 0.1037 - binary_accuracy: 0.9693 - val_loss: 0.1164 - val_binary_crossentropy: 0.1164 - val_binary_accuracy: 0.9642\n",
      "epoch:  30\n",
      "auc:  0.993868259969\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 169s - loss: 0.0948 - binary_crossentropy: 0.0948 - binary_accuracy: 0.9721 - val_loss: 0.4362 - val_binary_crossentropy: 0.4362 - val_binary_accuracy: 0.8952\n",
      "epoch:  31\n",
      "auc:  0.969986657667\n",
      "APatK:  0.89139737653\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 171s - loss: 0.1162 - binary_crossentropy: 0.1162 - binary_accuracy: 0.9652 - val_loss: 0.1230 - val_binary_crossentropy: 0.1230 - val_binary_accuracy: 0.9627\n",
      "epoch:  32\n",
      "auc:  0.993621746893\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.1016 - binary_crossentropy: 0.1016 - binary_accuracy: 0.9695 - val_loss: 1.1905 - val_binary_crossentropy: 1.1905 - val_binary_accuracy: 0.8213\n",
      "epoch:  33\n",
      "auc:  0.920936340535\n",
      "APatK:  0.819876946188\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.1013 - binary_crossentropy: 0.1013 - binary_accuracy: 0.9708 - val_loss: 0.2292 - val_binary_crossentropy: 0.2292 - val_binary_accuracy: 0.9262\n",
      "epoch:  34\n",
      "auc:  0.983513890066\n",
      "APatK:  0.982449410581\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.0925 - binary_crossentropy: 0.0925 - binary_accuracy: 0.9712 - val_loss: 0.1097 - val_binary_crossentropy: 0.1097 - val_binary_accuracy: 0.9654\n",
      "epoch:  35\n",
      "auc:  0.993999773644\n",
      "APatK:  1.0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.1124 - binary_crossentropy: 0.1124 - binary_accuracy: 0.9654 - val_loss: 0.6393 - val_binary_crossentropy: 0.6393 - val_binary_accuracy: 0.8864\n",
      "epoch:  36\n",
      "auc:  0.944338508433\n",
      "APatK:  0.796381691996\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 169s - loss: 0.1060 - binary_crossentropy: 0.1060 - binary_accuracy: 0.9677 - val_loss: 0.1159 - val_binary_crossentropy: 0.1159 - val_binary_accuracy: 0.9637\n",
      "epoch:  37\n",
      "auc:  0.993897024832\n",
      "APatK:  0.99706856165\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 168s - loss: 0.0947 - binary_crossentropy: 0.0947 - binary_accuracy: 0.9701 - val_loss: 0.1536 - val_binary_crossentropy: 0.1536 - val_binary_accuracy: 0.9592\n",
      "epoch:  38\n",
      "auc:  0.991278141174\n",
      "APatK:  0.97974661165\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 167s - loss: 0.1135 - binary_crossentropy: 0.1135 - binary_accuracy: 0.9664 - val_loss: 0.9240 - val_binary_crossentropy: 0.9240 - val_binary_accuracy: 0.8377\n",
      "epoch:  39\n",
      "auc:  0.918124570153\n",
      "APatK:  0.832455150826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "model = reccurent_model()\n",
    "\n",
    "X_test = [title_test[:10000, :], desc_test[:10000, :], nontext_matrix_test[:10000, :]]\n",
    "y_test = target_test[:10000]\n",
    "\n",
    "for epoch_num in range(40):\n",
    "    indices = np.arange(title_train.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = [title_train[indices[:10000], :], desc_train[indices[:10000], :], nontext_matrix_train[indices[:10000], :]]\n",
    "    y_train = target_train[indices[:10000]]\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=1, verbose=1, validation_data=(X_test, y_test), shuffle=True)\n",
    "    res = model.predict(X_test)\n",
    "    print(\"epoch: \", epoch_num)\n",
    "    print(\"auc: \", roc_auc_score(y_test, res))\n",
    "    print(\"APatK: \", APatK(y_test, res[:, 0], K=int(y_test.shape[0] * 0.025) + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  39\n",
      "auc:  0.916444880257\n",
      "accuracy:  0.842736363636\n",
      "APatK:  0.832586552646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_test = [title_test, desc_test, nontext_matrix_test]\n",
    "y_test = target_test\n",
    "res = model.predict(X_test)\n",
    "print(\"epoch: \", epoch_num)\n",
    "print(\"auc: \", roc_auc_score(y_test, res))\n",
    "print(\"accuracy: \", accuracy_score(y_test, np.round(res)))\n",
    "print(\"APatK: \", APatK(y_test, res[:, 0], K=int(y_test.shape[0] * 0.025) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the monster\n",
    "\n",
    "Since we have several data sources, our neural network may differ from what you used to work with.\n",
    "\n",
    "* Separate input for titles: RNN\n",
    "* Separate input for description: RNN\n",
    "* Separate input for categorical features: обычные полносвязные слои или какие-нибудь трюки\n",
    " \n",
    "These three inputs must be blended somehow - concatenated or added.\n",
    "\n",
    "* Output: a simple binary classification\n",
    " * 1 sigmoidal with binary_crossentropy\n",
    " * 2 softmax with categorical_crossentropy - essentially the same as previous one\n",
    " * 1 neuron without nonlinearity (lambda x: x) +  hinge loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lasagne'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c618843c8194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lasagne'"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import lasagne\n",
    "from theano import tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 inputs and a refere output\n",
    "from theano import tensor as T\n",
    "\n",
    "title_token_ids = T.matrix(\"title_token_ids\",dtype='int32')\n",
    "desc_token_ids = T.matrix(\"desc_token_ids\",dtype='int32')\n",
    "categories = T.matrix(\"categories\",dtype='float32')\n",
    "target_y = T.ivector(\"is_blocked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "title_inp = Input(shape=(title_tr.shape[1],), dtype='int32', name='main_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_inp = lasagne.layers.InputLayer((None,title_tr.shape[1]),input_var=title_token_ids)\n",
    "descr_inp = lasagne.layers.InputLayer((None,desc_tr.shape[1]),input_var=desc_token_ids)\n",
    "cat_inp = lasagne.layers.InputLayer((None,nontext_tr.shape[1]), input_var=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Descriptions\n",
    "\n",
    "#word-wise embedding. We recommend to start from some 64 and improving after you are certain it works.\n",
    "descr_nn = lasagne.layers.EmbeddingLayer(descr_inp, input_size=len(token_to_id)+1, output_size=?)\n",
    "descr_nn = RNN or LSTM over embedding, maybe several ones in a stack\n",
    "\n",
    "# Titles\n",
    "title_nn = <Process titles somehow (title_inp)>\n",
    "\n",
    "# Non-sequences\n",
    "cat_nn = <Process non-sequences(cat_inp)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = <merge three layers into one (e.g. lasagne.layers.concat) >                                  \n",
    "\n",
    "nn = lasagne.layers.DenseLayer(nn,your_lucky_number)\n",
    "nn = lasagne.layers.DropoutLayer(nn,p=maybe_use_me)\n",
    "nn = lasagne.layers.DenseLayer(nn,1,nonlinearity=lasagne.nonlinearities.linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "* The standard way:\n",
    " * prediction\n",
    " * loss\n",
    " * updates\n",
    " * training and evaluation functions\n",
    " \n",
    " \n",
    "* Hinge loss\n",
    " * $ L_i = \\max(0, \\delta - t_i p_i) $\n",
    " * delta is a tunable parameter: how far should a neuron be in the positive margin area for us to stop bothering about it\n",
    " * Function description may mention some +-1  limitations - this is not neccessary, at least as long as hinge loss has a __default__ flag `binary = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All trainable params\n",
    "weights = lasagne.layers.get_all_params(nn,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simple NN prediction\n",
    "prediction = lasagne.layers.get_output(nn)[:,0]\n",
    "\n",
    "#Hinge loss\n",
    "loss = lasagne.objectives.binary_hinge_loss(prediction,target_y,delta = what_do_you_think).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weight optimization step\n",
    "updates = <your favorite optimizer>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinitic prediction \n",
    " * In case we use stochastic elements, e.g. dropout or noize\n",
    " * Compile a separate set of functions with deterministic prediction (deterministic = True)\n",
    " * Unless you think there's no neet for dropout there ofc. Btw is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deterministic version\n",
    "det_prediction = lasagne.layers.get_output(nn,deterministic=True)[:,0]\n",
    "\n",
    "#equivalent loss function\n",
    "det_loss = <an excercise in copy-pasting and editing>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coffee-lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[loss,prediction],updates = updates)\n",
    "eval_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[det_loss,det_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "* The regular way with loops over minibatches\n",
    "* Since the dataset is huge, we define epoch as some fixed amount of samples isntead of all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#average precision at K\n",
    "\n",
    "from oracle import APatK, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Out good old minibatch iterator now supports arbitrary amount of arrays (X,y,z)\n",
    "\n",
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    batchsize=kwargs.get(\"batchsize\",100)\n",
    "    shuffle = kwargs.get(\"shuffle\",True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield [arr[excerpt] for arr in arrays]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaking guide\n",
    "\n",
    "* batch_size - how many samples are processed per function call\n",
    "  * optimization gets slower, but more stable, as you increase it.\n",
    "  * May consider increasing it halfway through training\n",
    "* minibatches_per_epoch - max amount of minibatches per epoch\n",
    "  * Does not affect training. Lesser value means more frequent and less stable printing\n",
    "  * Setting it to less than 10 is only meaningfull if you want to make sure your NN does not break down after one epoch\n",
    "* n_epochs - total amount of epochs to train for\n",
    "  * `n_epochs = 10**10` and manual interrupting is still an option\n",
    "\n",
    "\n",
    "Tips:\n",
    "\n",
    "* With small minibatches_per_epoch, network quality may jump around 0.5 for several epochs\n",
    "\n",
    "* AUC is the most stable of all three metrics\n",
    "\n",
    "* Average Precision at top 2.5% (APatK) - is the least stable. If batch_size*minibatches_per_epoch < 10k, it behaves as a uniform random variable.\n",
    "\n",
    "* Plotting metrics over training time may be a good way to analyze which architectures work better.\n",
    "\n",
    "* Once you are sure your network aint gonna crash, it's worth letting it train for a few hours of an average laptop's time to see it's true potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "minibatches_per_epoch = 100\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    #training\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    \n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_tr,title_tr,nontext_tr,target_tr,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch:break\n",
    "            \n",
    "        loss,pred_probas = train_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Train:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "    \n",
    "    #evaluation\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_ts,title_ts,nontext_tr,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch: break\n",
    "        loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Val:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"If you are seeing this, it's time to backup your notebook. No, really, 'tis too easy to mess up everything without noticing. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "Evaluate network over the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#evaluation\n",
    "epoch_y_true = []\n",
    "epoch_y_pred = []\n",
    "\n",
    "b_c = b_loss = 0\n",
    "for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "    iterate_minibatches(desc_ts,title_ts,nontext_tr,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "    loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "\n",
    "    b_loss += loss\n",
    "    b_c +=1\n",
    "\n",
    "    epoch_y_true.append(b_y)\n",
    "    epoch_y_pred.append(pred_probas)\n",
    "\n",
    "\n",
    "epoch_y_true = np.concatenate(epoch_y_true)\n",
    "epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "\n",
    "final_accuracy = accuracy_score(epoch_y_true,epoch_y_pred>0)\n",
    "final_auc = roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "final_apatk = APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "\n",
    "print \"Scores:\"\n",
    "print '\\tloss:',b_loss/b_c\n",
    "print '\\tacc:',final_accuracy\n",
    "print '\\tauc:',final_auc\n",
    "print '\\tap@k:',final_apatk\n",
    "score(final_accuracy,final_auc,final_apatk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main task\n",
    "\n",
    "* https://goo.gl/forms/eJwIeAbjxzVuo6vn1\n",
    "* Feel like Le'Cun:\n",
    " * accuracy > 0.95\n",
    " * AUC > 0.97\n",
    " * Average Precision at (test sample size * 0.025) > 0.99\n",
    " * And perhaps even farther\n",
    "\n",
    "* Casual mode\n",
    " * accuracy > 0.90\n",
    " * AUC > 0.95\n",
    " * Average Precision at (test sample size * 0.025) > 0.92\n",
    "\n",
    "* Remember the training, Luke\n",
    " * Dropout, regularization\n",
    " * Mommentum, RMSprop, ada*\n",
    " * etc etc etc\n",
    " \n",
    " * If you have background in texts, there may be a way to improve tokenizer, add some lemmatization, etc etc.\n",
    " * In case you know how not to shoot yourself in the foot with RNNs, they too may be of some use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
